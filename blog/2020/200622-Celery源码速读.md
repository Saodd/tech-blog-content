```json lw-blog-meta
{"title":"Celery源码速读","date":"2020-06-22","brev":"【弃坑】Celery是python世界中最主流的异步任务框架。","tags":["Python","源码","坑"],"path":"blog/2020/200622-Celery源码速读.md"}
```



## 弃坑感言

本来在我的理解中，celery这种异步任务执行框架，源码应该不会特别复杂才对。其核心逻辑就是 发送/监听任务-执行任务-储存结果，无非就是实现几个功能：

- 将函数包装为任务，一端发送任务，一端执行任务。
- 队列、优先级控制。
- 参数与结果的序列化与反序列化。
- 执行端的并发，效率提升。

唯一的复杂性可能会落在与不同消息中间件之间的兼容上，但是只要设计合理，这部分其实并不重要，使用者只需要挑选他们常用的一种适配器来阅读就可以了。

但是打开celery的源码看了半天，我承认我是懵逼了。它的源码中有各种稀奇古怪的概念，以及反人类的动态加载语法。

是不是因为我太菜才看不懂呢？于是我上网搜索一下，发现也有不少人与我有相同的感想。所以结论很明显，是写它的人太菜了（狗头）

总之是先弃坑。我打算自己实现一个简易版的框架，自己踩踩坑，再来看看能不能对celery有更好的理解。

## 项目概况

开源在[Github](https://github.com/celery/celery)上。选用的是`BSD`开源许可，截止目前有 15.2k star。

官方对这个框架的定义是：简单、灵活、可靠的分布式异步任务队列系统。

自动化测试方面做了蛮多事情的，不过看到标签上最近一个修复bug依然是测试未通过的状态哈哈哈。（可能python的项目就是比较难做吧）

本文阅读的 Celery 代码是`4.3.0`版本，截止目前（2020-06-16）最新版本是`4.4.5`。本文阅读的 Python 版本是 `3.7.7`。

## 基本使用

既然是分布式异步任务，那就肯定至少有两个及以上的进程在运行了。Celery的实现模型是 `生产者 - 消息中介 - 消费者`，我们在实际项目中可能会选用 `Redis` 作为消息中介(或者用`RabbitMQ`更专业)，然后生产者和消费者一般都写在同一个项目中（共享一部分代码，用不同的命令启动）。

基本使用方式在我前面有一篇文章有简单介绍。这里看一下[官方](https://docs.celeryproject.org/en/latest/getting-started/first-steps-with-celery.html)最简单的例子：

```python
# ./task.py
from celery import Celery

app = Celery('my_app', broker='redis://localhost:6379/0')  # 根据个人情况修改

@app.task
def add(x, y):
    return x + y
```

上面定义了一个异步任务叫`add`，只要在前面加一个装饰器就能把普通函数封装为一个异步任务，这一点还是比较简单的。

然后我们用`celery`命令来启动一个消费者（`worker`）（下面命令中，tasks是模块名，在这里就是文件名）：

```shell
$ celery -A tasks worker --loglevel=info
```

保持消费者进程不要退出。最后我们用python命令行来启动一个生产者。注意调用的是`.delay()`这个方法，如果直接call的话会变成同步输出：

```text
>>> from tasks import add
>>> add.delay(4, 4)
<AsyncResult: a4e02183-af1b-4393-ac42-79b6b529feaa>

>>> add(4, 4)
8
```

此时我们可以在消费者上观察到日志输出如下，最后一个数字`8`是异步任务的返回值：

```
# ......
[2020-06-16 14:29:57,054: INFO/MainProcess] Received task: tasks.add[d05e04e9-6315-410d-9a1a-5205875b7661]  
[2020-06-16 14:29:57,057: INFO/ForkPoolWorker-8] Task tasks.add[d05e04e9-6315-410d-9a1a-5205875b7661] succeeded in 0.0005559210000001258s: 8
```

另外值得一提的是，默认的任务队列是存放在redis数据库中的`"celery"键`对应的列表中的。

## 1. 启动worker

在 Celery 的术语中，worker 其实是对应的 consumer（消费者）的概念。

我们通过客户端启动时，执行的是`celery/__main__.py`中的main函数。顺带一提，如果需要用自己的代码启动，可以用如下的方式：

```python
from tasks import app

if __name__ == '__main__':
    argv = ['worker', '--loglevel=INFO']
    app.worker_main(argv)
```

不管通过哪种方式启动，都会进入到一个`Command.execute_from_commandline`这个方法中：

```python
class Command(object):
    """Base class for command-line applications.
    """
    def execute_from_commandline(self, argv=None):
        # 参数可以手动指定，也可以读取自命令行参数
        if argv is None:
            argv = list(sys.argv)
        # 预留的并发补丁位置
        self.maybe_patch_concurrency(argv)
        self.on_concurrency_setup()

        # Dump version and exit if '--version' arg set.
        self.early_version(argv)
        try:
            argv = self.setup_app_from_commandline(argv)
        except：
            pass  # 省略此处代码

        self.prog_name = os.path.basename(argv[0])
        return self.handle_argv(self.prog_name, argv[1:])  # 正式执行
```

最后在`Command.__call__`方法中正式开启苦工生活：

```python
class Command(object):
    def __call__(self, *args, **kwargs):
        random.seed()  # maybe we were forked.
        self.verify_args(args)
        try:
            ret = self.run(*args, **kwargs)  # 在这里阻塞执行
            return ret if ret is not None else EX_OK
        except:
            pass # 略
```

然后这个`run`方法是由各个子类重写的。我们这里的 worker 的类就是 `bin.worker.worker`。然后它又实例化了另一个概念叫 `apps.worker.worker`，然后调用它的 `start`方法运行。

```python
class worker(Command):
        def run(self, argsxxxxxx, **kwargs):
        # 处理并发库补丁
        # 处理一些参数

        worker = self.app.Worker(argsxxxxxx, **kwargs)  # 这个app是我们在代码中实例化的Celery对象
        worker.start()  # 在这里阻塞运行
        return worker.exitcode
```

```python
# apps/worker.py
class Worker(WorkController):
```

```python
# worker/worker.py 
class WorkController(object):
    def start(self):
        try:
            self.blueprint.start(self)  # 这里阻塞运行……
        except WorkerTerminate:
            self.terminate()
        except Exception as exc:
            logger.critical('Unrecoverable error: %r', exc, exc_info=True)
            self.stop(exitcode=EX_FAILURE)
        except SystemExit as exc:
            self.stop(exitcode=exc.code)
        except KeyboardInterrupt:
            self.stop(exitcode=EX_FAILURE)
```

然后又出现了一个  `Blueprint` 类是什么鬼（心好累……）

```python
class Blueprint(object):
    def start(self, parent):
        self.state = RUN
        if self.on_start:
            self.on_start()  # 启动前处理一些东西
        for i, step in enumerate(s for s in parent.steps if s is not None):  # 循环运行……
            self._debug('Starting %s', step.alias)
            self.started = i + 1
            step.start(parent)
            logger.debug('^-- substep ok')
```

这里的 `parent` 是前面的 `WorkerController` ，然后它的`steps` 属性是来自于 `app`的：

```python
class WorkController(object):
    def setup_instance(self, argsxxxxx, **kwargs):
        # 略……
        self.steps = []
        self.on_init_blueprint()
        self.blueprint = self.Blueprint(
            steps=self.app.steps['worker'],
            on_start=self.on_start,
            on_close=self.on_close,
            on_stopped=self.on_stopped,
        )
```

关于 app 的构造我们后面再看。当前打断点可以截取出来 steps 的值是 `[<step: Hub>, <step: Pool>, <step: Consumer>]` 它们对应着不同的类，这些类可以在 `worker.components` 文件中找到。

（未完待续）

## 2. Celery对象的构造

回到我们的第一句代码：

```python
app = Celery('my_app', broker='redis://localhost:6379/0')
```

## 3. 包装任务函数
