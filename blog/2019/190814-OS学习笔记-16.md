```yaml lw-blog-meta
title: OS学习笔记16：内存虚拟化-底层机制-碎片
date: "2019-08-14"
brev: 引入碎片机制来更加灵活地管理内存。
tags: [OS]
```


# 第十六章 <机制：碎片 Segmentation>

[PDF链接](http://pages.cs.wisc.edu/~remzi/OSTEP/vm-segmentation.pdf)

按照之前的内存分配模型，在每个地址空间的堆栈之间都会有一块空闲的内存被浪费了。

**关键问题：如何支持一个巨大的地址空间？**

## 16.1 碎片：通用化的基底/上限模型 Generalized Base/Bounds

原理很简单，就是给每个`逻辑内存碎片logical segment`都安排一对`基底-上限base and bounds`计数器。这允许OS把碎片放在物理内存的不同位置，以此避免浪费。

比如对于一个典型的程序（Code，heap，stack三部分），我们可以将其分别放在物理内存的三个位置：

![Figure 16.2](/static/blog/2019-08-14-Fig-16-2.png)

## 16.2 我们访问的是哪个碎片

一种常见的方法是，我们显式地将地址的一部分位数来代表碎片编号，剩下的用来表示`偏离值offset`（即片内地址）.比如在上面的例子中，我们有3个碎片，所以需要前面两位来表示碎片编号：

![Figure 16.3](/static/blog/2019-08-14-Fig-16-3.png)

然后做一些这样的事情来检查并返回物理地址：

```text
// get top 2 bits of 14-bit VA
Segment = (VirtualAddress & SEG_MASK) >> SEG_SHIFT
// now get offset
Offset = VirtualAddress & OFFSET_MASK
if (Offset >= Bounds[Segment])
    RaiseException(PROTECTION_FAULT)
else
    PhysAddr = Base[Segment] + Offset
    Register = AccessMemory(PhysAddr)
```

另一种方法是，我们隐式地、让硬件来判断。比如如果是基于程序计数器PC偏离得来的，那就是Code碎片；如果是基于栈的，那就是stack碎片；其他的就是heap碎片。

## 16.3 栈怎么处理

我们知道，栈是从高向低延申的，所以我们需要设置一个方向。

![Figure 16.4](/static/blog/2019-08-14-Fig-16-4.png)

## 16.4 允许共享

为了节省内存，有时需要在不同的地址空间之间共享内存，比如Code碎片就肯定可以。于是增加一个`保护位protection bits`：

![Figure 16.5](/static/blog/2019-08-14-Fig-16-5.png)

## 16.5 细粒度与粗粒度 Fine-grained vs. Coarse-grained

我们现在所说的是粗粒度，只分为了Code，stack，heap三个碎片。但是有的操作系统支持更细的划分，但是这也要求硬件上的进一步支持。

## 16.6 OS支持

第一是上下文切换，对的，需要将所有的碎片寄存器都保存下来。

第二是碎片大小变化时的处理。比如堆内存不够了，就要systemcall，OS会提供更大的内存、更新碎片寄存器、并吧结果返回进程。要注意的是，如果内存不够了，OS会拒绝这个请求。

第三是如何管理空闲内存。我们移除那个假设，每个进程的地址空间大小都不一样的话，很快内存中就到处都是空洞了，我们称为`边界摩擦external fragmentation`。比如我们实际还有24KB，但是不连续，OS可能就会拒绝一个20KB的内存申请。

一个解决办法是`压缩compact`物理内存，即重新排列现有的碎片。但是这种操作非常昂贵，并且压缩后也会带来新的问题。

另一个简单的办法就是使用`空闲列表free-list`算法来管理，具体可能有成百上千种实现，经典的有`最适合best-fit`，`最不适合worst-fit`，`第一个适合first-fit`以及复杂的算法比如`兄弟算法buddy algo`。但没有哪一种能够绝对完美地解决边界摩擦问题。

## 16.7 小结

`碎片`解决了一些问题，帮助我们建立一个高效的虚拟内存。比起动态大小分配，碎片帮助我们减少浪费。还有一些比如code碎片共享，也帮助我们节约内存。

但是也存在问题，最大的是边界摩擦问题；然后是因为碎片大小可以变化，所以空闲内存管理变得困难。我们使用一些算法可以减轻，但不能避免。

还有一个更重要的问题，比如我们想要一个巨大的、但是很少使用的堆放在一个完整的碎片中，这就很浪费了。我们需要新的解决办法。
