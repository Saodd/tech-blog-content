```json lw-blog-meta
{"title":"OS学习笔记23：完整的虚拟内存系统","date":"2019-08-21","brev":"完整地看一下内存虚拟化的实现。","tags":["OS"],"path":"blog/2019/190820-OS学习笔记-23.md"}
```



# 第二三章 <完整的虚拟内存系统>

[PDF链接](http://pages.cs.wisc.edu/~remzi/OSTEP/vm-complete.pdf)

我们已经分别学习了一些关键要素，包括页码表，TLB，硬盘交换区等。但是，一个完整的内存虚拟化系统还有很多特性，包括性能方面、功能方面和安全方面。

**关键问题：如何构建一个完整的虚拟内存系统？有哪些特性可以用于改善？**

我们将介绍两个系统。一个是最早的现代化内存管理器VAX/VMS系统，它对后世影响深远。
第二个就是Linux，因为它是目前广泛应用的系统，并且在无论是手机等小型设备还是规模化的多核处理系统都能高效运行。

## 23.1 VAX/VMS

VMS是1970年当时的巨头DEC公司的产品，虽然公司倒闭了，但是产品很牛逼。这个VMS系统要适应低端到高端机器的需求，并且还能掩盖硬件设计的瑕疵，非常值得学习。

### 内存管理硬件

VAX-11电脑提供32bits虚拟地址空间，每页512bytes；因此前23位是页码后9位是偏移；同时，页码前2bits用于碎片划分。

地址空间的后半截是每个进程独享的，称为`进程空间process space`。进程空间的前半部分(P0)用于放置用户程序以及堆heap；进程空间的后半部分(P1)是栈stack。

地址空间的前半截，叫做`系统空间system space`（S）。受保护的OS代码和数据放在这里，并且OS通过这种方式在不同进程间共享。

有个很大的问题是页面太小了，512bytes是历史原因保留的，所以这对页码表产生了很大的挑战。他们想了两个办法：一是使用碎片将用户地址空间分成两半；二是把用户页码表放在内核的虚拟内存中，OS在自己的碎片区S中为页码表分配内存，当内存不足时放到交换区中。

把页码表放在OS内存中，会导致地址翻译变得更加复杂。

### 真实的样子

![Figure 23.1](/static/blog/2019-08-20-Fig-23-1.png)

注意，当上下文切换的时候，OS只替换P0和P1的寄存器地址，而不更新S的地址，以此实现共享。

在每个地址空间中共享内核空间有一些好处。这会让内核的工作更简单，比如调用write()这个systemcall的时候，可以很轻易地复制数据。这使得内核对于进程来说就像库函数一样。

另一个需要注意的问题是保护问题。VAX在页码表中安排了保护位，CPU只有在内核态才可以访问保护位的数据。

### 页面替换

VAX的PTE信息包含：1位有效位，4位保护位，1位脏位，5位保留位，然后就是PFN。注意，没有引用位！也就是说，它的页面替换算法必须要在没有硬件支持的情况下选择页面。

开发者还要考虑`内存占用大户memory hogs`。而我们之前学习的策略是没有针对大户的限制的。

所以采用了`碎片化先进先出segmented FIFO`替换政策，即每个进程有一个页面数量的最大限额(`resident set size`)，当超过限额的时候，第一个页面自然就被踢出去了。

但是我们知道FIFO有很多缺点，所以又添加了两个`复活区second-chance lists`（干净区和脏区），所有将要被替换的页面不会直接被驱逐，而是先放进复活区的末尾。复活区是全局的。
当另一个进程请求页面时，从干净复活区头部取出一页来用；而如果原来的进程再次请求复活区中的页面，那它可以接着用，就避免了交换区的硬盘读写损耗。

还使用聚合来优化硬盘写入性能。

### 其他的技巧

`按需求清零demand zeroing`和`只在写时复制copy-on-write`，我们称这类为`懒惰优化lazy optimizations`。

`按需求清零`意思就是只有当进程真正使用页面的时候才分配内存并清零内存。`只在写时复制`用于将页面从一个地址空间复制到另一个空间的时候，先不复制而是在两边都标记为只读，当有写入请求的时候才真正复制。

只在写时复制（COW）对于UNIX系统非常重要，因为fork()和exec()是需要从原来的进程复制数据的，因此不去实际复制将是非常有用的。（译者注：这解答了我的疑问）

## 23.2 LINUX

我们这里只讨论一些重要的并且先进的思想。我们只讨论Intel x86架构的实现。

### Linux地址空间

与VAX和其他现代OS一样，Linux的地址空间也包括用户部分和内核部分。

![Figure 23.2](/static/blog/2019-08-20-Fig-23-2.png)

在典型的32位Linux中，地址空间以`0xC0000000`分界，即四分之三给用户，剩下给内核。64位版本相似但是不同。

一个有趣的地方是内核空间分为两个部分。一个是`内核逻辑区kernel logical addresses`，这是普通的内核虚拟地址，内核通过kmalloc来分配这块空间。绝大多数的内核数据结构都放在这里，比如页码表，（每个进程对应的）内核栈等等。与其他内存不同的是，内核逻辑区不允许交换到硬盘中。

内核逻辑区与物理内存的联系很有意思。内核逻辑区直接映射到物理内存的第一部分上，比如`0xC0000000`翻译为`0x00000000`，`0xC0000FFF`翻译为`0x00000FFF`等。这意味着：翻译内核逻辑区地址很简单（可以看作就是物理内存空间）；连续的虚拟地址也对应着连续的物理地址（有利于一些操作比如IO）。

另一个部分是`内核虚拟区kernel virtual address`，内核通过vmalloc来分配这块空间。这块空间是虚拟的，并不连续。

内核虚拟区的意义是允许32位Linux内核拥有超过1GB的内存。不过对于64位Linux没意义了。

### 页码表的结构

`x86`架构提供了硬件管理的多级页码表结构。OS只是在进程启动、退出、上下文切换时设置一下相关的变量即可。

最大的变化是过渡到64位。目前64位只用了48位作为地址空间，其中12位偏移量（因为页面大小4KB）和36位页码（分为4级，每级9位，因为PTE的长度也增长到8bytes）

![Figure 23.2.1](/static/blog/2019-08-20-Fig-23-2-1.png)

想象一下，以后内存再次扩容的话，最多会有6级页码表。（译者注：到那时页面大小也一定会调整，以减少页码表的级数。此时依然保留4KB是为了减少页面内摩擦浪费，当内存容量拓展到64位的时候，一定能够容忍更大的页面内摩擦）

### 大页面支持

`x86`最大支持1GB大小的页面，这种页面在Linux中称为`巨型页面huge pages`。

巨型页面的好处是充分利用TLB的缓存容量。还有利于改善TLBmiss的情况，以及加速内存的分配。

有趣的是Linux是如何**逐步地**实现巨型页面支持的。因为一开始很明确只有少数应用（比如数据库）强烈需求这个特性，所以一开始必须显式地要求申请巨型页面才行（比如`mmp()`或者`shmget()`），对于其他的应用依然正常使用4KB页面。随着巨型页面流行起来，Linux才将巨型页面的支持转换为`隐式的transparent`，开启这项特性后OS会自动尝试分配巨型页面（一般是2MB，但有些系统会给1GB），而不用更改应用程序代码。

巨型页面也有一些代价，比如内部摩擦问题，比如交换时的巨大开支等。不过总的来说4KB页面已经不像以前那样普遍了（大家都开始用巨型页面了）。

### 页面缓存

为了减少在访问持久数据时的开销，Linux也采用了缓存。

Linux的`页面缓存page cache`是统一的，有三个主要来源：内存映射的文件、设备中的文件数据和元数据、储存着进程信息的堆栈（称为`匿名内存anonymous memory`）。这些东西都放在`页面缓存哈希表pafe cache hash table`，可以快速访问。

页面缓存会区分净/脏的页面，脏页面会定期在后台写入硬盘中。可以设置定时和定量写入。

Linux使用改良版的`2Q`替换算法来选择哪些页面去交换区。之前的LRU算法有个问题，如果某个大文件（比内存大）一直被访问，那么LRU会把其他的页面全都踢出去。

`2Q`算法建立两个列表。当页面第一次访问时，会放入`不活跃列表inactive list`；当第二次访问时，放入`活跃列表active list`。需要踢出页面时，优先从不活跃列表中选择。还会周期性地把活跃列表底部的页面移回不活跃列表，保持活跃列表占总页面大小的三分之二。每个列表都是使用一些粗糙版本的LRU以减少损耗，比如时钟算法。



### 安全性与缓冲区溢出

现代OS与古代不同的很重要一点是安全性。越来越多的内部关联机制大大强化了安全性。

一个重要的威胁就是`缓冲区溢出buffer overflow`。OS一般会相信用户输入不会太大，然后将用户输入复制到缓冲区中；但是这是一个漏洞，如果输入内容太大，有可能溢出并写入到其他的位置中去。比如复制程序长这样就糟糕了：

```c
int some_function(char *input) {
    char dest_buffer[100];
    strcpy(dest_buffer, input); // oops, unbounded copy!
}
```

一个防御手段就是阻止计算机执行来自指定区域的代码。还记得保护位中有一位执行位吗（rwx），就是这样用的。

但是这还不够。攻击者可能会通过函数返回点来获取程序控制，称为`面向返回点编程return-oriented programming (ROP)`。即尝试覆盖写入大量的代码，污染进程栈或者是C库等，当某个函数返回时可能刚好会定位到恶意代码的位置，从而被恶意代码控制。

Linux使用了`地址空间层随机化address space layout randomization (ASLR)`的办法来防御这种攻击，即每次分配的内存地址完全随机：

```c
int main(int argc, char *argv[]) {
    int stack = 0;
    printf("%p\n", &stack); // 每次地址都不一样
    return 0;
}
```

这个办法很有用，所以内核也使用了这个办法，称为KASLR，但是这又引来了更大的问题，我们后面再说。

### 其他安全问题：Meltdown And Spectre

当前（2018年8月）面临着两个新的安全攻击：`Meltdown`和`Spectre`。他们利用了CPU的一个性能优化机制叫`预测执行speculative execution`，即预测接下来可能要执行什么指令并提前执行。

这个机制的问题在于，它倾向于在系统的各个部分(如处理器缓存、分支预测器等)中留下执行的痕迹，这种痕迹会让内存变得脆弱，即使我们认为MMU正在保护内存。

一种解决办法是从每个用户进程中删除尽可能多的内核地址空间，为大多数内核数据创建一个单独的内核页表，称为`内核页表隔离kernel pagetable isolation (KPTI)`。这意味着每次回到内核态都要切换页码表，代价很大。

但是内核页表隔离不能根治。另一个简单的办法就是关闭预测执行机制，也不行，这会让执行速度下降几千倍。

## 23.3 小结

至此你已经从上到下地了解了内存虚拟化。并且学习了一点点Linux的知识。

现在的Linux已经非常庞大并且复杂，但很多东西还是继承自古老的优秀思想。比如Linux也用了`copy-on-write`的懒惰机制、零页(`/dev/zero`)、后台页面交换服务(`swapd`)等。
