```yaml lw-blog-meta
title: Python代码优化小技巧
date: "2019-07-23"
brev: 接上篇面试感悟，在这里把最近在项目中遇到的代码优化案例总结下来。
tags: [Python]
```


## 前言：性能计算方法

```python
def wrap_timeit(func):
    def _inner(*args, **kwargs):
        g = {"func": func, "args": args, "kwargs": kwargs}
        num = 100
        duration = timeit.timeit("func(*args, **kwargs)", globals=g, number=num) / num
        print(duration)

    return _inner
```

我们创建一个16k+行的.csv文件，每个字段在每一行都填充满（没有空值）。
利用以上的装饰器，在timeit()中运行100次取平均值。

## `Pandas`库相关

### 筛选优化：startswith

假如我们要实现下面的功能：

```python
# 把['BBG Ticker'].startswith('USD/TWD')的行标记出来， 其他的洗掉，然后把POS的值复制到'Closing Balance'中
    vc['Mark'] = vc['BBG Ticker'].apply(lambda x: 'ndf' if x.startswith('USD/TWD') else '')
    a = vc[vc['Mark'] == 'ndf'].index
    if len(a) != 0:
        vc.loc[a, 'Closing Balance'] = vc.loc[a, 'Pos']
    else:
        print('[Warning] no ndf.')
```

以上写法是在`'Mark'列`打上标记，然后对标记的行进行复制操作。但是效率很低：

1. 使用`lambda`+`apply()`来遍历，效率比较低；
2. 对所有行都进行了擦写操作（‘ndf’或者‘’）；
3. 增加了一列`Mark`，需要额外的空间；
4. 截取了一个副本（`vc[vc['Mark'] == 'ndf'].index`）来获取索引

我们可以简化为这样：

```python
    a = vc["BBG Ticker"].str.startswith("USD/TWD")
    vc.loc[a, "Closing Balance"] = vc.loc[a, "Pos"]
```

二者之间的性能区别：

```python
@wrap_timeit
def old_code(vc: pandas.DataFrame):
    vc['Mark'] = vc['BBG Ticker'].apply(lambda x: 'ndf' if x.startswith('USD/TWD') else '')
    a = vc[vc['Mark'] == 'ndf'].index
    if len(a) != 0:
        vc.loc[a, 'Closing Balance'] = vc.loc[a, 'Pos']
    else:
        print('[Warning] no ndf.')

@wrap_timeit
def my_code(vc: pandas.DataFrame):
    mark_index = vc["BBG Ticker"].str.startswith("USD/TWD")
    if mark_index.any():
        vc.loc[mark_index, "Closing Balance"] = vc.loc[mark_index, "Pos"]
    else:
        print("[Warning] no ndf.")

# 输出：
# 0.009849900000000023
# 0.008031599999999917  # 优化后大概提升20%
```

很意外，性能只提升了一点点，并没有数量级的差异……但是（强行辩解）这个写法就自然了很多！对不对！

### 筛选优化：isin

```python
@wrap_timeit
def old_code(df: pandas.DataFrame):
    df = df[(df['book'] == 'V0001') | (df['book'] == 'V0002') | (df['book'] == 'V0003')]

@wrap_timeit
def my_code(df: pandas.DataFrame):
    df = df[df['book'].isin(["V0001", "V0002", "V0003"])]

# print
# 0.003595242
# 0.0009478440000000011  # perfmc + 50%~80%
```

### 两列关联计算

我们的数据库中的交易信息，有一列`side`储存了sell/buy的方向，但是计算的时候要把方向融合进`volume`中，才利于求和。

```python
@wrap_timeit
def old_code(df: pandas.DataFrame):
    a = df[df['side'] == 'Sell'].index  # 把sell的交易，改为负数
    if len(a) != 0:
        df.loc[a, 'volume'] = df.loc[a, 'volume'] * (-1)

@wrap_timeit
def my_code(df: pandas.DataFrame):
    df["volume"] *= df["side"].apply(lambda x: -1 if x=="Sell" else 1)

@wrap_timeit
def my_code2(df: pandas.DataFrame):
    df.loc[df["side"] == "Sell", "volume"] *= -1

# print
# 0.004962222999999999
# 0.00477529
# 0.003401843  # perfmc + 20~30%
```

### 遍历行

一般我们对于同一行中的数据操作，可以用两个`Series`直接运算就可以了；
但有的时候也会有一些特殊需求，必须逐行遍历。

那我们看一下几种遍历方式的性能差别：

```python
@wrap_timeit
def old_code(df: pandas.DataFrame):
    for id in df.index:
        df.loc[id, "settle"] = df.loc[id, "ClosingBalance"] * df.loc[id, "volume"]


@wrap_timeit
def my_code(df: pandas.DataFrame):
    for index, s in df.iterrows():
        s["settle"] = s["ClosingBalance"] * s["volume"]

@wrap_timeit
def my_code2(df: pandas.DataFrame):
    for s in df.itertuples():
        df.loc[s.Index, "settle"] = s.ClosingBalance * s.volume

# print
# 5.091893033333333
# 0.9296266666666669   # iterrows() is very fast, and rows are mutable
# 4.1758492333333335   # itertuples() is faster, but tuples are immutable
```

> 要注意的是，`for index, series in df.iterrows()`这种写法，返回的行对象虽然是可以修改的
> （通过`series[colname]=newvalue`来修改），但是修改后的结果并不会返回原来的Dataframe中。
> 也就是说，返回的行是一个新的对象，对这个新对象的任何操作不会影响原来的表。  
> 所以我认为一般情况下都用`itertuples()`比较好（修改值一律使用`df.loc[]`）。

我们看看`iterrows()`与`itertuples()`的性能差距：

```python
@wrap_timeit
def my_code(df: pandas.DataFrame):
    for index, s in df.iterrows():
        settle = s["ClosingBalance"] * s["volume"]

@wrap_timeit
def my_code2(df: pandas.DataFrame):
    for s in df.itertuples():
        settle = s.ClosingBalance * s.volume

# print
# 0.7889746666666667
# 0.009843933333333332  # 100 times faster
```

### 应对pycharm没有提示的bug

`Pandas`是一个非常庞大的第三方库，它有多种对象（常用的有`Dateframe`,`Series`等），
所以它有很多函数都是泛型设计。

比如典型的有`def concat(objs, ...) -> any`；

像这个函数就有一些缺陷，对我影响最大的是，它的返回类型是`any`，如果我有这样一个操作：

```python
df = pandas.DataFrame()
df = pandas.concat([dfa, dfb], ignore_index=True)
```

那么，我后面再对df进行操作，就无法利用pycharm提供的类型提示了。

这个时候只要加一行：

```python
assert isinstance(df, pandas.DataFrame)
```

就可以恢复正常了：

![pycharm](https://saodd.github.io/tech-blog-pic/2019/2019-07-23-Python-PandasDataframe.png)

## 工作日计算小技巧

在我们金融行业中，工作日（交易日）是一个很重要的概念。

有些东西是与工作日无关的（比如利息，或者比特币这种7*24小时交易），而有些是与工作日密切相关的
（股票清算，期货逐日结算等）。

一般能想到的办法是维护一个函数，或者维护一个表格。

```python
# 项目中的旧代码
def get_last_work_day(date):
    a = date.isoweekday()
    if a in range(1, 6):
        if a == 1:
            date = date - timedelta(3)
        else:
            date = date - timedelta(1)
    print(date)
    return date.strftime('%Y%m%d')
```

代码优雅与否先不讨论，更重要的是在逻辑上会产生很多问题：

 - 法定节假日怎么办？
 - 大陆放假，其他国家/地区不放假怎么办

我们不可能设计一个函数来计算法定节假日，更不可能为每个国家/地区都维护一个。

所以想到一种简便方法：**使用`MongoDB`来实现**。

主要思路就是以日期为索引，每个国家/地区为列名，储存True/False值。

初始化的时候，我们就以weekday来写入初值就好了。每当遇到节假日的时候，我们手动进入数据库修改一下
（这里推荐`Mongo-Express`），非常简单。

如何使用：

```python
r = self.mgclc.find({"Date": {"$lt": today.strftime("%Y-%m-%d")}, "Workday": 1}).sort("Date", -1).limit(2)
last_workday = datetime.strptime(r[1]["Date"], "%Y-%m-%d")
```

Q&A：

 - 为什么使用`MongoDB`？
   - 因为`pymongo`面向对象的接口编程，非常爽。
 - 能不能使用别的，比如`MysqlDB`？
   - 当然，不过你可能要在SQL语句上花一点点点点心思；而且在增/删列的时候会有一点麻烦
 - 使用文件储存这个表格怎么样？
   - 当然，不过文件系统相比于数据库，可访问的范围就小得多了（数据库通过tcp端口连接，几乎可以从任何位置访问）；而且，你要维护好读取并转化这个表格的函数，并且引入你的代码中。
