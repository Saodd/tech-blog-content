```lw-blog-meta
{"title": "[官方] Getting to Go: The Journey of Go's Garbage Collector", "date": "2019-11-20", "tags": ["Golang"], "brev": "该博客发布时间 2018-07-12。一直想要详细了解一下 Go 的 GC，奈何网上资料很少，都说的是 Go1.5 的机制。所以还是要来看看官方的文章才行。"}
```

# Getting to Go: The Journey of Go's Garbage Collector

[原始链接](https://blog.golang.org/ismmkeynote)

Rick Hudson  
12 July 2018

## 摘要

Go语言的特性、目标和用例迫使我们重新思考整个垃圾收集堆栈，并让我们惊讶。来讲一下我们是如何、以及为什么这样做。

## 个人传记

Richard L. Hudson (Rick) 是内存管理领域的巨佬，也是Go团队的成员，负责Go的垃圾回收和运行时。

## 演讲记录

首先我们要了解一下从GC的角度看，Go是什么样子的。首先，Go程序可以有几十万个堆栈。它们由调度器管理，并且总是在GC安全点上被抢占。我们通过复制栈和更新栈中的指针来管理栈及其大小。这是一个局部操作，所以它的伸缩性很好。

### Go是面向值的

Go是『面向值`value-oriented`』的语言，像C，而不是面向引用的。我们看一个例子，这个`Reader`数据体中，所有的数值都是线性摆放的。这让程序员有更灵活的内存管理手段，以及更好地支持缓存局部性。

![2019-11-20-Go-GC-value-oriented.png](/static/blog/2019-11-20-Go-GC-value-oriented.png)

这样的机制，还对C++接口非常有利。很显然，Google有大量的基础设施目前还是C++写的，不可能一步到位全部换成Go，所以必须高效支持外部函数接口。

这样的设计，也对Go的运行时产生了奇妙的影响。这也是Go与其他GC语言最重要的区别。

### Go允许内部指针

即允许一个外部指针，指向结构体中的某个成员值。例如`b = &reader.blk`。

### 静态提前编译

我们使用提前编译系统，这样二进制文件就包含了整个运行时。所以不支持JIT（译者注：即时编译系统，如Java）

### GC参数

一个是`GCPercent`，可以调节你想使用多少CPU和你想使用多少内存。另一个是`MaxHeap`，还未正式发布，它允许程序员设置最大的堆大小。

### Go运行时发展历史

在2014年之前，GC延迟还是Go的生存威胁。如果没有解决这个问题，Go语言也就没有今天的成功。其他语言也有类似的问题。比如Rust使用了另一种机制。

GC延迟很重要。举个例子，假如延迟小于10ms的GC过程只占99%，假如每个Web会话发起100次请求，那么最后只有37%的用户能够享受到低于10ms的延迟；假如要保证99%的用户都获得低延迟，那么要将GC的保证率做到99.99%。

我们把这个问题称为『9的独裁`tyranny of the 9s`』。在2014年Jeff Dean发表了一篇文章《The Tail at Scale》，这篇文章很重要。

目前流行的解决方案是，当GC运行时，服务会拒绝请求并将其发往其他服务实例。这个方案只是回避了问题（而且会带来大量性能损耗），而Google要解决这个问题。

### GC算法

最初的计划是做『`barrier free concurrent copying GC`』，但是它的性能损耗还不确定，因此Go希望避免它。我们难以在一年以内把整个编译器做好性能改进，因此我们决定放弃`copying`部分。

最后决定做『三色并发算法`tri-color concurrent algorithm`』。这可以解决STW（stop the world）问题。我们还关心编译速度。

### 尺寸分隔

把堆内存按照尺寸来分隔，有很多好处，比如少碎片。虽然分配速度会稍微慢一些，不过没关系。

但是一个问题是内部指针。GC必须要准确地找到对象的起始点。

### 对象元数据

『`Object meta-data`』，我们对每个对象都需要维护一些信息，因为我们没有`header`（译者注：应该是指有些语言实现会在对象前面保存对象元数据）。

有一些`Mark bits`，其中包含2bit用于说明对象其中是指针还是数值，等等（不展开讲）。

### 写屏障

『`write barrier`』，只在GC运行期间生效。在GC运行期间，某个全局变量会变得不同，此时写屏障开始生效，确保不会误删了可到达`reachable`对象。

### GC频率控制器`Pacer`

它基本上是基于一个反馈循环来决定何时最好地开始一个GC循环。

由于标记过程和写屏障的分配是并行的，因此`Pacer`要控制分配速度不能超过标记速度（否则永远标记不完）。如果需要，它可以减慢分配速度并提高标记速度，即通过gorutine的分配数量来控制。

### 成功！

在1.4版本，GC延迟大约300ms；到1.5版本，下降到30-40ms；到1.6.3版本，下降到4-5ms。

到1.7版本，在18GB堆内存的情况下，延迟时间依然压缩在2-3ms上下。到1.8之后，甚至控制在1ms以内了。

值得提醒的是，有很多非GC因素也会影响GC延迟，但是没关系了，正如谚语所说：“您不必比熊更快，只需比旁边的人更快即可。”

### 但是也有失败

> Scars are just tattoos with better stories. 伤疤只是带有更好故事的纹身。

#### 面向请求的垃圾收集 ROC

『`Request Oriented Collector` (ROC)』，意思是，对于那些与请求、或者死亡的Go程相关的的对象，往往会比其他的对象（比如全局变量）死的更快。

一个典型场景就是RPC（比如REST），当一个请求完成后，执行的Go程可能会返回一个全局变量；但是剩下很多在栈上的局部变量其实都可以直接回收了。回收栈上的变量是一个局部操作，如果用前面所说的全局三色标记回收算法，由于写屏障一直打开，性能会差一些。

虽然ROC有一些好处，但是也会带来坏处。比如Go编译器就是典型的、ROC不利的场景。我们有两三百个性能测试场景，在不少场景下，开启ROC都会带来比较严重的性能损失（30%-50%数量级）。

总体来说，ROC对于硬件核心数的拓展性支持良好。也许在未来某一天，我们主流硬件有128个核心，那么ROC会是非常有利的；但是在目前主流4-12核心的情况下，我们还是决定放弃ROC。

#### 分代垃圾回收

『`generational GC`』，是个老生常谈了。（思路与Python的稍有不同，但也不展开讲了）

分代GC可以在一部分场景获得性能提升，但是在另一些场景会造成性能负担。

最重要的是，随着我们Go编译器的进步，我们做逃逸分析的能力越来越强。即，我们能够将更多的对象放在栈上。也就是说，逃逸分析把分代GC的工作抢掉了很多，因此分代就没有太大意义了。
用户在接受面向价值的方法方面越来越聪明，指针的数量也在减少。数组和映射保存的是值，而不是指向结构体的指针。一切都是好的。

分代GC的真正价值在于减少STW时间。但是前面说过了，现在的Go的STW已经很短了，现在关注的重点在于吞吐量。

### 展望未来

我们都知道摩尔定律。但是最近几年，计算机性能翻倍的时间越来越慢长了。

在内存领域，我们会发现，目前`容量`依然保持相对较高增速，`带宽`增长相对较慢。从经济角度来说，扩充容量也是合理的选择。

那么这些未来发展趋势，如何指导Go语言的发展？

1. 提升可靠性。我们不会放过任何BUG。我们希望把调度器调得更紧凑一些，以获得更好的确定性和公平性，但我们不想牺牲任何性能。
2. 维持GC设计模型。因为我们已经研究了十几年了，目前觉得很满意。
3. 继续优化逃逸分析。
4. 优化写屏障。从算法上。
5. 最后，也是最重要的，我们希望在接下来的5年里，甚至是未来的10年里，我们能够驾驭摩尔定律中RAM优于CPU的趋势。

P.S. Go团队正在招聘！（译者注：大概看了下谷歌的职位，职位要求挺普通的，没有年限也没写薪资，可能主要看的是年限与能力的匹配度和天赋能力吧）

## 我的总结

看这篇文章的目的是为了了解Go的GC原理。现在已经清楚了，主要算法是三色标记算法，GC与主程序并发运行，GC启动时会有写屏障，最后STW时间特别短，典型值是0.5ms，一切看起来都很酷。

也有一些缺点，比如没有ROC设计，在远程调用RPC场景下不够完美，但应该也是可以接受的程度。
