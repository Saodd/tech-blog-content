```json lw-blog-meta
{"title":"OS学习笔记18：内存虚拟化-分页","date":"2019-08-15","brev":"忘掉碎片，来看一下分页技术吧。","tags":["OS"],"path":"blog/2019/190815-OS学习笔记-18.md"}
```



# 第十八章 <介绍：分页 Paging>

[PDF链接](http://pages.cs.wisc.edu/~remzi/OSTEP/vm-paging.pdf)

`碎片segmentation`技术有着很大的问题，因为是把空间都分为大小不等的碎片，因此会加剧碎片之间的`摩擦fragmented`。

所以我们考虑第二个方案：把内存划分为一些大小相等的小块，即所谓的`分页pagin`技术，每一片我们叫做一`页page`，因此我们可以把内存看作是由很多页组成，即`帧page frames`，每一帧包含一页。

**关键问题：如何划分页？如何最小化时空损耗？**

## 18.1 从简单的例子开始

我们想象一个64bytes大小的地址空间，它分为4页：

![Figure 18.1](https://raw.githubusercontent.com/Saodd/Saodd.github.io.backup-Jun2020/master/static/blog/2019-08-15-Fig-18-1.png)

而在物理内存上，这4页可能是任意摆放的：

![Figure 18.2](https://raw.githubusercontent.com/Saodd/Saodd.github.io.backup-Jun2020/master/static/blog/2019-08-15-Fig-18-2.png)

所以分页技术的优势就体现出来了：我们不用关心进程如何使用地址空间，也不用考虑堆栈的方向问题，等等。

另一个优点就是：简单。OS可能管理着一个freelist，当需要内存的时候，只需要任意取出4个就可以了。

为了管理页，OS要维护一个数据结构，我们叫做`页码表page table`，其中主要要存放地址翻译信息。注意，页码表是给每个进程分别维护的。

好的，现在想象一下当进程需要访问内存，比如从内存拷贝到寄存器：

```x86asm
movl <virtual address>, %eax
```

为了翻译这个`virtual address`，我们要把它分为两部分：`虚拟页码virtual page number(VPN)`和`页内偏移量offset`。按上面图片中的例子，如果地址空间总共64bytes，那么我们只需要6bits就可以表示了：

![Figure 18.2.1](https://raw.githubusercontent.com/Saodd/Saodd.github.io.backup-Jun2020/master/static/blog/2019-08-15-Fig-18-2-1.png)

前面两位是虚拟页码，然后在页码表中索引就可以得到`物理帧码physical frame number(PFN)`（或者叫物理页码），然后就能找到物理地址了。

![Figure 18.3](https://raw.githubusercontent.com/Saodd/Saodd.github.io.backup-Jun2020/master/static/blog/2019-08-15-Fig-18-3.png)

## 18.2 页码表储存在哪

页码表可以变得非常大，比之前的碎片技术中的base/bounds寄存器信息大得多。比如在32位系统中，可能由20位作为VPN，而12位作为页内偏移量。

这意味着，假如我们每个页需要4bytes来保存入口信息，那每个页码表的大小就是4MB。所以我们不放在MMU中，而是放在内存中。

现在，假设页码表存放在OS管理的内存中，并且待会我们会看到OS内存可以虚拟化，甚至放进硬盘中的交换区。

## 18.3 页码表里到底有什么

可以用任意的数据结构。最简单的是`线性页码表lineat page table`，通过索引VPN就可以获得PFN。

至于PTE的结构，包含：
- 1位`验证位valid bit`用于说明这个翻译是否有效（比如堆和栈中间的空位都会标记为`无效invalid`）。
- `保护位protection bits`用于控制读写执权限；
- 1位`存在位present bit`表示这一块在内存上还是在硬盘交换区中；
- 1位`脏位dirty bit`表示这一页自从放入内存中以来是否被修改；
- 1位`引用位reference bit`（accessed bit）表示这一页是否存在引用（会影响`页面替换page replacement`）；

![Figure 18.5](https://raw.githubusercontent.com/Saodd/Saodd.github.io.backup-Jun2020/master/static/blog/2019-08-15-Fig-18-5.png)

> 你可能注意到以上Intel的例子中，并没有验证位的存在，因为它和存在位合并了。当存在位0时，会引发陷阱指令到OS去执行。

## 18.4 太慢了

在以上描述的模型中，OS要先把虚拟地址换算为物理地址（VPN），然后物理地址（PFN）还要找到页面入口（PTE）。

为了实现以上操作，硬件需要知道页码表在哪里，所以安排了一个`寄存器page-table base register`，然后硬件每次都这样翻译：

```c
VPN = (VirtualAddress & VPN_MASK) >> SHIFT
PTEAddr = PageTableBaseRegister + (VPN * sizeof(PTE))
```

在上面的例子（2位页码，4位偏移）中，`VPN_MASK`设为`110000`，`SHIFT`就是4.就得到了虚拟页码，然后换为物理页码。然后再用以下方式取得偏移量并拼接：

```c
offset = VirtualAddress & OFFSET_MASK
PhysAddr = (PFN << SHIFT) | offset
```

现在已经实现了一个最基本的分页地址翻译算法，虽然性能惨不忍睹。完整代码：

```c
// Extract the VPN from the virtual address
VPN = (VirtualAddress & VPN_MASK) >> SHIFT

// Form the address of the page-table entry (PTE)
PTEAddr = PTBR + (VPN * sizeof(PTE))

// Fetch the PTE
PTE = AccessMemory(PTEAddr)

// Check if process can access the page
if (PTE.Valid == False)
    RaiseException(SEGMENTATION_FAULT)
else if (CanAccess(PTE.ProtectBits) == False)
    RaiseException(PROTECTION_FAULT)
else
    // Access is OK: form physical address and fetch it
    offset = VirtualAddress & OFFSET_MASK
    PhysAddr = (PTE.PFN << PFN_SHIFT) | offset
    Register = AccessMemory(PhysAddr)
```

## 18.5 内存追踪 A Memory Trace

举一个例子来追踪分页技术下的内存访问结果：

```c
int array[1000];
for (i = 0; i < 1000; i++)
    array[i] = 0;
```

```shell-session
prompt> gcc -o array array.c -Wall -O
prompt> ./array
```

看一下汇编代码是如何实现的：

```x86asm
1024 movl $0x0,(%edi,%eax,4)
1028 incl %eax
1032 cmpl $0x03e8,%eax
1036 jne 0x1024
```

- 1024代码将0存入数组的内存地址中，其中%edi是数组的基础地址，%eax是递增的索引；
- 1028代码递增索引；
- 1032代码将当前索引与索引上限1000进行比较；
- 1036代码检查比较结果，如果不相等那就跳回1024代码。

为了理解内存访问的过程，我们假设虚拟地址空间是64KB大小，每一页是1KB；假设由一个线性页码表，放在物理地址的1KB位置。

首先考虑一下Code指令放在哪里。很显然是第二页（指令从1024-1036），那么VPN=2；假设这一页映射在PFN=4上。

然后考虑这个数组，它有4000bytes大，假设是在\[40000:44000\]的虚拟地址，那么VPN=39,40,41,42；假设映射在PFN=7,8,9,10上。

然后开始分析内存访问过程：

每条指令抓取，都需要两次内存访问：一次去读页码表，第二次去物理地址读取指令。同时，`movl`指令涉及到了数组的内存，所以又需要一次访问页码表，二次访问数组元素地址。

以下图片显示了5次循环中的内存访问情况，每次循环涉及10次内存访问：

![Figure 18.7](https://raw.githubusercontent.com/Saodd/Saodd.github.io.backup-Jun2020/master/static/blog/2019-08-15-Fig-18-7.png)

## 18.6 小结

可以看到，分页有很多好处：减少摩擦，易于划分和管理。

但是，也会导致性能下降，以及空间浪费（页码表占用）。接下来的章节我们看一下如何优化。
