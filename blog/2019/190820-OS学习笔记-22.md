```yaml lw-blog-meta
title: OS学习笔记22：内存虚拟化-交换区政策
date: "2019-08-21"
brev: 该替换哪一页呢？这是个问题。
tags: [OS]
```


# 第二二章 <超越物理内存限制 Beyond Physical Memory: Mechanisms>

[PDF链接](http://pages.cs.wisc.edu/~remzi/OSTEP/vm-beyondphys.pdf)

在`内存紧张memory pressure`的情况下，OS会开始将内存中的页面交换进入硬盘中。选择哪些页面？这个问题是由`替换政策replacement policy`决定的。

**关键问题：OS如何选择页面？**

## 22.1 缓存管理

研究政策之前先仔细描述一下我们的问题。既然内存持有着一部分的页面，那么我们可以认为内存是硬盘的缓存。

因此我们的问题就变成了，如何最小化`缓存未命中cache miss`，或者最大化`缓存命中cache hit`。然后引入一个指标叫`平均内存访问时间(AMAT)`，公式为：

AMAT = T<sub>M</sub> + (P<sub>Miss</sub> · T<sub>D</sub>)

`TM`表示每次访问内存的时间，`TD`表示每次访问硬盘的时间，`PMiss`表示不能从内存中访问的概率（miss概率）。

假设未命中率10%，内存访问时间100ns，硬盘访问时间10ms，那么

AMAT = 100ns + 0.1*10ms ~= 1ms

## 22.2 最优替换政策

为了评价某种替换政策是否有效，我们要先定义一个理想的政策。有人定义了，即“将最远才会被访问到的页面替换”就是最优解。但是说着容易，做起来很难！

> 找到算法的最优解是很重要的，当你的算法足够接近于理论极限值，你就可以停下了！

举个例子，假设某个进程访问页面的顺序是0, 1, 2, 0, 1, 3, 0, 3, 1, 2, 1，然后缓存只有3页，那么会像这样：

![Figure 22.1](/static/blog/2019-08-20-Fig-22-1.png)

前面三页都是miss，因为缓存中一开始啥也没有，我们称其为`冷启动cold-start miss`（或者`强制compulsory miss`）；

然后当我们访问页面3时，需要替换一个了，替换哪个？按照顺序数下去，最远的页面是2，那么就换掉2；后面同理换掉3.于是理论最优命中率就是54.5%了（如果排除冷启动的情况，命中率将是85.7%）。

但是我们在实践中不可能知道进程访问页面的顺序。所以我们要想点别的办法。

## 22.3 简单的政策：先进先出FIFO

早期系统用这个政策。优点是简单。我们还是用上面的例子来测试一下：

![Figure 22.2](/static/blog/2019-08-20-Fig-22-2.png)

相比之下，命中率只有36.4%（57.1%），不太理想。

## 22.4 随机政策

随机比FIFO好一些，但是实践中肯定要看运气，并不可靠。

## 22.5 根据历史情况：LRU

前面两种政策有个问题：他们可能会把重要的页面踢出去，导致后面又要加载回来。

参考我们在调度政策中的思想，我们依靠历史使用数据来指导我们的选择。

一种政策是，根据`频率frequency`，访问频率越高的就别替换了。
另一种更常用的政策是，根据`崭新度recency`来判断，越是最近访问过的就别替换了。

这些`政策家族family of policies`被称为`地点法则principle of locality`，主要思想就是观测程序或进程的行为。于是有了`最少访问频率政策Least-Frequently-Used (LFU)`。

还是用之前的例子，可以看到与理想情况一样：

![Figure 22.5](/static/blog/2019-08-20-Fig-22-5.png)

除此以外，还有`最高访问频率MostFrequently-Used (MFU)`和`最近访问Most-Recently-Used (MRU)`政策。

## 22.6 在指定负荷下的表现

首先一种`负荷workload`，假设是没有`地点性locality`的（即随机访问页面），可以看到这几种政策的表现几乎一致：

![Figure 22.6](/static/blog/2019-08-20-Fig-22-6.png)

- 当工作负荷没有地点性，那么政策根本无所谓；
- 当缓存足够大，那么政策根本无所谓；

另一种负荷，假设是`二八负荷80-20`，80%的访问去向20%的页面（`热页hot`），剩下20%的访问去向80%的页面（`冷页cold`）

![Figure 22.7](/static/blog/2019-08-20-Fig-22-7.png)

从上图可以看到，LRU表现很好，因为它更倾向于保留“热页”，优化了缓存命中率。但是这种相对的优化并不是绝对的，还是要看实际情况。

比如下面一个极端的例子，即按顺序循环访问50个页面的负荷，表现就很糟糕：

![Figure 22.8](/static/blog/2019-08-20-Fig-22-8.png)

## 22.7 那么，如何实现呢

基于历史数据的算法再正常情况下表现良好，但是如何实现呢？

以LRU作为例子。每次页面访问（内存访问）时，都要更新某个数据结构（计数或者移动顺序）。注意，是每次访问。因此我们要慎重考虑一下。

一个优化的办法是依靠硬件的帮助。比如，为每个页维护一个时间戳，每次访问的时候更新一下。但是，这种办法并不现实，因为扫描整个数组代价太大了。

## 22.8 粗糙的LRU

所以现代的OS只是实现了一个粗糙版本的LRU。

需要依靠硬件的帮助，使用1bit即所谓的`使用位use bit`（或者叫`引用位reference bit`）。每次访问页面的时候，硬件会给这一页标上`1`；但是硬件并不会给它归零，而由OS负责归零。

OS有很多算法来实现粗糙的LRU，其中一种是`时钟算法clock algorithm`。想象所有的页面都安排在一个环形列表中，一个`指针clock hand`指向某个点作为起点。
当需要替换页面时，OS从起点开始，逐个扫描每一页是否标记为1；如果是1，那么就设为0；如果为0，那就可以替换。

![Figure 22.9](/static/blog/2019-08-20-Fig-22-9.png)

## 22.9 考虑脏页

对于上面的时钟算法有一个改进，就是考虑`脏页dirty page`（即是否被写入）。原因是：如果某个页面被修改了（即脏了），那这些修改也要写入硬盘，那损耗很大；如果页面是干净的，那么从内存中驱逐出去就很轻松。

## 22.10 其他政策

页面替换并不是唯一的内存虚拟化的政策。比如，OS还要考虑何时(when)将页面载入内存中，即所谓的`页面选择政策page selection policy`。

对大多数页面来说，系统只在页面被访问的时候载入内存；当然，OS也会进行预测，然后提前载入一些页面，即所谓的`预读prefetching`。比如，可以考虑提前加载当前页面的下一页。

还有一种政策需要考虑，那就是OS如何将页面写入硬盘。当然可以是逐个写入；也可以是积累一些`写入任务pending writes`在内存中，然后再一起写入。这种政策称为`聚集clustering`或者`分组grouping`。

## 22.11 颠簸Thrashing

还有最后一个问题：当一批正在运行的进程，所需求的内存超过了OS能够提供的，怎么办？这种情况下，OS会不停地进行页面交换操作（并显著影响性能），我们称为颠簸。

早期系统有一个好办法，即停止运行一些进程，以期待剩下的进程所需的内存能够小于物理内存容量。我们称其为`入场许可admission control`。

现代OS更加严厉。比如有些Linux版本会直接启用`内存溢出杀手out-of-memory killer`，它会选择一个占用内存很大的进程杀掉。这会带来一些问题，比如杀死了一些系统关键进程导致影响我们操作。

## 22.12 小结

至此我们学习了一些页面替换政策（以及其他政策）。现代OS一般都是在LRU的基础上加一些补丁，比如时钟政策，或者`扫描抵抗resistance`政策，比如ARC。

但是，随着内存与硬盘性能差异越来越大，上述算法越来越没用，因为写入硬盘代价太大了。所以现在最好的解决办法就是：多买几条内存条吧！
