```json lw-blog-meta
{"Title":"网络学习笔记3：传输层","Date":"2019-10-15","Brev":"第二层，传输层，主要是TCP/UDP。","Tags":["网络"]}
```



# 第三章 Transport Layer

这一层很重要，分为TCP和UDP两种。

## 3.1 传输层服务简介

传输层协议提供的一种『逻辑通信`logical communication`』。意思是从上层应用程序看来，不同（主机的）进程之间是直接相连的；应用程序不需要去操心下面的网络通信实现。

注意，传输层协议是在网络终端上执行的，路由器不管。路由器只会检查到网络层协议。

从发送的角度来看，传输层将应用层的消息包转化为传输层的消息包，即『片段`segments`』。这个过程（可能会）将应用层数据包切段，然后分别加上传输层header。然后传到下面的『网络层`network layer`』。

在接收时同理，从网络层获取片段，将其组装后发回给应用层。

### 3.1.1 传输层与网络层的关系

传输层负责在**进程**之间建立逻辑联系，而网络层负责在**主机**之间建立逻辑联系。

> 译者注：书上用了3页来打比喻……

### 3.1.2 总览

在网络领域术语中，我们有时将TCP数据包称为『片段`segments`』，而将UDP数据包称为『报文`datagram`』，我们在本书中统一称为片段。但是要注意，我们还将**网络层**数据包也称为『报文`datagram`』！

我们还要先简单讲一下网络层协议，它只有一个协议『IP协议』，即`Internet Protocol`。它负责在主机之间建立逻辑联系，并提供『尽力投递服务`best-effort delivery service`』，即只尽力而不保证。既不保证传递顺序，也不保证完整性。每个主机至少有一个网络层地址，即IP地址。我们在这里暂时只需要知道一个主机有一个IP地址。

回到传输层协议。这个将『主机-主机』拓展为『端口-端口』的过程称为『传输层多路复用`transport-layer multiplexing`』和『多路分解`demultiplexing`』。TCP/UDP还提供完整性校验。

事实上，UDP只提供两项服务：多路复用(分解)和错误检查。它并不保证传输的可靠性。

TCP提供更多服务，包括：流量控制、顺序编号、确认、计时器，以此保证传输的可靠。还提供『拥塞控制`congestion control`』，这不是针对某项应用的服务，而是在整个网络内生效的机制；简单的说，就是尽量保证所有连接能够享受相同的带宽。

## 3.2 多路复用与分解

传输层从网络层收到数据包后，不是直接传给上层应用程序，而是传给套接字。每个套接字都有唯一的辨识器。

每个segment里都有一些字段来描述应该由哪个套接字来接收。检查这些字段并发往相应的套接字的过程，就是分解；从套接字接收数据并分割写入字段的过程，就是复用。

在这些字段中，会包含『源端口号』和『目的端口号』，端口号是16bit数字，取值范围[0,65535]；其中，[0,1023]被称为『公认端口号`well-known port numbers`』，它们是被保留作专门用途的。（具体标准请参阅[RFC 3232](http://www.iana.org)）

```text
               <- 32bits ->
    |----------------|----------------|
    | Source port#   |  Dest. port #  |
    |----------------|----------------|
    |     Other header fields         |
    |---------------------------------|
    |                                 |
    |   Application data (message)    |
    |                                 |
    |---------------------------------|
```

### 无连接的复用/分解

回顾一下上一章写的UDP代码：

```python
clientSocket = socket(socket.AF_INET, socket.SOCK_DGRAM)
```

通过这种方式建立UDP套接字，传输层会自动给这个套接字分配一个端口号；具体地说，UDP会从[1024,65535]这个范围内选择一个未被其他UDP端口占用的号码。开发人员也可以显式地指定：

```python
clientSocket.bind(("", 19157))
```

注意，UDP套接字可以被一个（IP，端口）的二元元组充分描述。

那么源地址的作用是什么呢？就是方便服务端进行回复。

### 有连接的复用/分解

先看一下TCP套接字，它由四元元组来描述（源IP，源端口，目标IP，目标端口）。因此，当一个TCP片段到达主机时，要使用全部四个字段来定位到相应的套接字。

注意，来自不同源地址但发往相同目标地址的片段，在UDP中会被发往同一个UDP套接字，而在TCP中会被发往不同的TCP套接字。（译者注：即在UDP中需要应用程序自己区分源地址，TCP帮你根据源地址分好类了）

### 关于Web服务器

Web服务器规定在80端口监听。现代的高性能服务器一般使用线程来处理TCP连接套接字。

如果客户端和服务端使用『持久连接`persistent HTTP`』，那在连接有效期内所有消息都通过这个套接字进行；如果是非持久连接，那么每次请求都要创建/销毁套接字，这对于性能影响非常严重。

## 3.3 无连接传输：UDP

如果要你来独立设计一个基本的传输层协议，你会怎么做？当然，最简单的想法可以是直接将应用层数据发到网络层，然后直接将网络层数据发到传输层。

但是这样一个协议没能完成这一层的基本职责：负责多路复用/分解，将host-host的数据包准确地发送到相应的端口。

事实上，UDP就是一个非常非常基础的协议，它仅仅只实现了端口转发，和少量的错误处理。当程序员选择使用UDP而不是TCP时，应用程序其实基本上就是在直接与IP协议对话。UDP从应用层接收数据包后，只会添加源端口、目的端口、和另外两个字段，然后传给网络层。

DNS是一个使用UDP的典型例子。当DNS应用需要查询记录时，就会创建一条消息并通过UDP发送。如果没有收到回复（可能是底层弄丢了请求或者回复），DNS应用程序可以再次发起请求，或者通知上层的应用程序。

既然TCP提供有保障的传输，那为什么要用UDP？

- 提供更好的传输控制。（在应用程序层面，说白了就是越简单的工具越容易DIY）UDP接收数据之后会马上发出去，而TCP有拥塞控制可能会限流。
- 无需建立连接。可以免去三次握手延迟。
- 没有连接状态。TCP维护着连接状态，包括缓冲区、拥塞控制参数、顺序号和验证参数，这些都是要消耗内存和计算资源的。
- 更小的头部负担。TCP添加了20bytes的头部，而UDP只需要8bytes（4个字段，每个16bits）。

### 3.3.1 UDP片段结构

```text
               <- 32bits ->
    |----------------|----------------|
    | Source port#   |  Dest. port #  |
    |----------------|----------------|
    |   Length       |  CheckSum      |
    |---------------------------------|
    |                                 |
    |   Application data (message)    |
    |                                 |
    |---------------------------------|
```

`Length`字段说明了这个片段的长度（头部加上数据体），这个字段是必要的，因为每个片段的长度可能不同。

`CheckSum`字段用来校验传输是否发生了错误。准确的说，在IP协议中也有这个字段。

### 3.3.2 UDP校验和

校验和是用来检查每个bit是否出现了错误（在传输过程中受到干扰等）。

计算方法很简单，直接把（除了存放校验和的16bit以外的）所有的位相加就可以了，最后再用`1111111111111111`做一次减法，就能得到校验和。

你可能会奇怪，很多连接层协议也提供了校验和，为什么UDP也要检查？原因是连接层并不做保证，有可能使用的是不做校验和的协议。另外，在路由器的内存中也可能发生错误，所以UDP片段内再次检查也是好的。

但是注意，UDP虽然检查错误，但是并不恢复；有的会直接丢掉危险的数据包，而有时也会向上层发出警告。

## 3.4 可靠数据传输的法则

可靠数据传输向上层提供的是可靠的数据传输的通道，可靠的意思是没有bit错误，而且数据包的顺序也是正确的。

要实现可靠是很难的，因为下层的网络层协议是不可靠的。我们现在只讨论『单向数据传输`unidirectional data transfer`』，意思是只从发送端传输到接收端；而不讨论『双向数据传输`bidirectional`』（或者称全双工传输）。

### 3.4.1 建立一个可靠数据传输协议

我们一步一步来实现。

#### v1.0

我们先考虑一个最简单的情景，即假设下层协议是完全可靠的。这样的话协议非常简单，只需要简单地接收数据包然后转发出去就可以了。

#### v2.0

现在假设会出现bit错误（称为腐败）。这样我们需要引入『应答机制』，即对接收的数据包进行校验并作出肯定或否定的答复（`positive/negative acknowledgments`）。

总结一下，实现上述功能需要三个新的功能：

- 错误检查。这里选用比UDP更强大的技术，我们在后面的章节会讲。只需要知道会引入额外的字段长度。
- 反馈。根据校验的结果进行回复，用0表示NAK（否定），用1表示ACK（肯定）。
- 重传。发生错误时，发送方要能够重传。

但是，现在还有一个致命的缺陷：还没有对ACK/NAK数据包进行校验！如果这个包也腐败了怎么办？要求接收方重新应答吗？

- 思路一：设计一个新的消息种类，sender向reciever询问：“你刚刚说了啥？”这个思路很直观，但是要注意，这条消息依然可能腐败，导致问题越来越复杂。
- 思路二：使用一个额外的字段，储存另一个校验和，来允许接收方可以尝试“恢复”bit错误。
- 思路三：直接重发源数据包。但这会导致数据包重复问题，进而引起接收方的数据包顺序错乱。

我们选择方案三。并且额外增加一个『顺序号`sequence number`』在数据包里，以解决上述的顺序问题。

#### v3.0

现在，数据包不仅会腐败（被篡改），还有可能被丢失。

我们将检测丢包的任务交给发送方。无论是数据包丢了，还是答复包丢了，最终发送方都是没有收到答复的。这样，发送方只需要等待一定的时间，如果超时了就重发。

但是应该等待多长时间呢？很明显，至少要等一个正常的来回周期，加上接收方必要的反应时间。在因特网环境下，很难取一个最佳等待时间，只能选一个相对合理的数值。

这样，重发机制就是发送方的万能灵药了。为了实现重发，需要引入『计时器`countdown timer`』，以及相应的功能：①为每个数据包启动计时器；②处理计时器中断；③停止计时。

### 3.4.2 管道化的可靠数据传输协议

上面说的v3版本协议在功能上是正确的，但是性能非常糟糕，因为它每次只能处理一个数据包并且要等到肯定回复之后才能发送下一个。

解决办法就是：不停下来等待回复消息，而是立即发送下一个数据包。但是也要注意一些问题：

- 顺序号必须是递增的，因为每个传输中的数据包都必须有一个唯一的号码。
- 发送和接收都需要设置缓冲区（必须确认成功后才能移除）。
- 顺序号和缓冲区的大小是一个策略问题。基础的有`Go-Back-N`和`selective repeat`。

### 3.4.3 Go-Back-N (GBN)

GBN协议，发送方可以发送多个数据包而不需要等待答复，但是对未确认的最大数量有限制N。

![2019-10-15-GBN.png](/static/blog/2019-10-15-GBN.png)

![2019-10-15-GBN-2.png](/static/blog/2019-10-15-GBN-2.png)

如上图所示，我们也将其称为『滑动窗口协议`sliding-window protocol`』。

顺序号是固定长度的，并形成一个循环（用完后从零开始）。

GBN协议发送方必须响应三个事件：

- 上层调用。协议要检查窗口是否可用，如果不可用那就返回异常。一般应用程序应该有缓冲区或者使用同步机制来确保协议可用。
- 收到ACK。会记录在一个『累计确认数`cumulative acknowledgment`』中。
- 超时。会将所有未确认的数据包全部重发。收到任意确认消息后会重置计时器。

GBN接收方的动作很简单，收到数据包之后发回**最后一个包的顺序号**ACK就可以了。注意，接收方会丢掉所有不符合顺序的数据包（因为发送方会全部重发）。

![2019-10-15-GBN-3.png](/static/blog/2019-10-15-GBN-3.png)

### 3.4.4 Selective Repeat (SR)

GBN缺点很明显，如果延迟很大或者窗口设置很大，那么可能经常要重发大量的数据包，这是不必要的。

SR协议要求接收方对每个数据包作出单独的回复，这样发送方可以根据需要有选择地进行重发。

![2019-10-15-SR.png](/static/blog/2019-10-15-SR.png)

![2019-10-15-SR-2.png](/static/blog/2019-10-15-SR-2.png)

但是这其中也有个问题，既然发送方和接收方的窗口不同步，那么可能会出现同一个编号被认为是不同的数据包的情况。另外，由于因特网的复杂环境，“某个数据包在路由中迷路了很久很久最后还是到达了目的地”这种事情也是有可能发生的，但是也许这时候接收方的编号已经循环第二遍了，那么这个数据包很可能会被当做是有效的数据而被误用。

因此，协议必须要考虑这些问题，并且要假想一个『最大生存时间』，超过这个时间可以相信数据包已经死了。在TCP协议家族中一般设置为3分钟。

## 3.5 面向连接的传输：TCP

说完了可靠数据传输的一些基本内容，接下来我们完整的看一下TCP。

### 3.5.1 TCP连接

它之所以被称为面向对象，是因为进程在通信之前必须先『握手`handshake`』，在握手阶段会初始化一些『TCP状态变量』。 需要注意的是，连接只在两个终端上维护。

TCP是全双工服务：可以同时发送和接收。而且它是『点到点`point to point`』的，即不允许一个发送方发到多个接收方。

回想一下上一章写的代码，客户端通过`clientSocket.connect((serverName,serverPort))`来发起连接。客户端会发送一个特殊的TCP片段（片段指传输层数据包），服务端随后响应一个特殊的TCP片段，然后客户端再发一个特殊的TCP片段。这就是所谓的『三次握手`three-way handshake`』。注意，前面两个片段不会携带有效载荷（即应用层数据），从第三个片段开始才会。

应用程序通过套接字向TCP协议发送数据，TCP会将其放在发送缓冲区中（`send buffer`），并在“方便”的时候抓取数据打包发送出去。

![2019-10-15-TCP-buffer.png](/static/blog/2019-10-15-TCP-buffer.png)

片段的大小（`maximum segment size(MSS)`）是由下层协议限制的（即`maximum transmission unit, MTU`）计算时要减去TCP+IP头部大小（一般40bytes）。MMS一般可能是1500bytes。还可以尝试侦测路径上的最大MSS（`path MSS`），使用这个数值可以确保每个TCP片段可以放进一个帧（连接层数据包）里。

### 3.5.2 TCP片段结构

TCP片段也分为头部和数据部。数据部分是由MMS限制大小。例如在Telnet应用中，可能只包含1bytes数据，于是整个片段的大小只有21bytes。

```text
            <- 32bits ->
|------------------|------------------|
| Source port#     |  Dest. port #    |
|------------------|------------------|
|           Sequence number           |
|-------------------------------------|
|       Acknowledgment number         |
|-------------------------------------|
|  *many-fileds*   | Receive window   |
|-------------------------------------|
|Internet checksum |Urgent data pointer|
|-------------------------------------|
|                                     |
|                Options              |
|                                     |
|-------------------------------------|
|                                     |
|                Data                 |
|                                     |
|-------------------------------------|

*many-fileds*：
|-------------------------------------|
| Header-length | Unused  |   Flags   |
|-------------------------------------|
```

比UDP多出的部分是：

- 32bit的『顺序号`sequence number`』和32bit的『确认号`acknowledgment number`』;
- 16bit的『接收窗口`receive window`』用于流量控制，表面接受者愿意接收的字节数；
- 4bit的『头部长度`header-length`』用来说明头部的额外长度（即`Option`字段长度），这允许变长头部。后面的『选项`Option`』，一般长度是0。
- 6bit『标记`Flags`』

#### 顺序号和确认号

他们是TCP头部中最重要的字段，因为他们是可靠传输的关键。

TCP将数据视为无结构、有顺序的字节流，顺序号表明的是字节流的顺序而不是片段（数据包）的顺序。例如，应用层要发送一个500,000bytes的文件，并且MSS大小是1000bytes，那么TCP将其分为500个片段；第一个包的顺序号是0，第二个是1000（而不是1），以此类推。

那么确认号呢？确认号只会发送『下一个期待的字节号』。假如收到了(0,99)和(200,299)两个包而中间的丢失了，那么只会发回100作为确认号。

![2019-10-15-tcp-squence-acknowl.png](/static/blog/2019-10-15-tcp-squence-acknowl.png)

### 3.5.3 来回时间估计与超时

对于每个片段从发送出去到接收确认之间的时间，我们称其为『样本来回时间`SampleRTT`』。TCP协议一般不会为每个片段都计算这个时间，而是每次只计算一个（算完一个后再计下一个）。

为了估计一个『预估来回时间`EstimatedRTT`』，每次获取一个SampleRTT时都进行更新，公式如下：

```text
EstimatedRTT = (1 – α) • EstimatedRTT + α • SampleRTT
```

`α`的建议值是0.125（即1/8）。那么上述公式是什么意思呢，每次获取最新的延迟时间，用最新的时间去更新旧的预估时间，得到一个最新的预估时间。注意这个算法也称为『指数权移平均数`EWMA`』，意思是每个更新进去的元素，都在以指数的速度降低影响。

除了算一个预估来回时间，再算一个『来回时间偏离度`DevRTT`』，公式如下（`β`的建议值为0.25）：

```text
DevRTT = (1 – β) • DevRTT + β•| SampleRTT – EstimatedRTT |
```

我们看这张图就能理解什么是SampleRTT和EstimatedRTT了：

![2019-10-15-RTT.png](/static/blog/2019-10-15-RTT.png)

#### 重传超时间隔的设置与管理

原则来说，重传超时时间应该略大于EstimatedRTT。建议公式如下：

```text
TimeoutInterval = EstimatedRTT + 4 • DevRTT
```

TimeoutInterval的初始值建议是1秒；当出现超时了，它就翻倍。等收到第一个确认片段后，就用上述公式进行计算。

### 3.5.4 可靠数据传输

我们看一个简化的TCP模型，这里只考虑发送端的情况，并且只关注三个事件：应用层传递数据、计时器超时、收到确认片段。伪代码如下：

```text
NextSeqNum=InitialSeqNumber
SendBase=InitialSeqNumber

loop (forever) {
    switch(event)
        event: data received from application above
            create TCP segment with sequence number NextSeqNum
            if (timer currently not running)
                start timer
            pass segment to IP
            NextSeqNum=NextSeqNum+length(data)
            break;
        event: timer timeout
            retransmit not-yet-acknowledged segment with smallest sequence number
            start timer
            break;
        event: ACK received, with ACK field value of y
            if (y > SendBase) {
                SendBase=y
            if (there are currently any not-yet-acknowledged segments)
                start timer
            }
            break;
} /* end of loop forever */
```

#### 超时间隔翻倍

每当超时事件发生时，TCP会将顺序号最小的那个片段重发；但是此时不会重新根据公式计算时间间隔，而是将原先的间隔翻倍。

这种设计提供了一点点拥塞控制的功能（简单说就是减少了重发的频率）。

#### 快速重发

如果只是简单地等待超时间隔到来才重发，那可能会让整个等待时间变得很长。因此，发送方有一种检测机制，即发现到重复的确认号时（重复三次时），就可以立即重发未确认的片段。（回忆一下，假如有1、2、3三个片段，接收方如果没收到2，那么收到3的时候会重复发送1的确认号）

#### 全部重发还是选择重发

前面介绍过两种思路GBN和SR。因为TCP只记录一个『最老未确认顺序号』，因此不能实现选择重发SR；但是也不会直接按GBN的思路将所有后续片段全部重发，相反，TCP只发送最多一个片段（即那个最老的片段）。

一个改进TCP的标准是，接收方可以对不正确顺序号的片段进行确认（即告诉发送方有哪些后续片段已经收到了），发送方可以相应地进行重发，这样就很接近SR了。

### 3.5.5 流量控制

回顾一下，TCP为每个连接维护一个接收缓冲区。但有时上层应用程序不会立即读取缓冲区，那如果发送方继续发送，很容易就要溢出了。

因此发送方要维护『接收窗口`receive window`』这个概念。接收方通过两个变量`LastByteRead`和`LastByteRcvd`来动态计算接收窗口的大小，并通知发送方。

那么接收方如何告诉发送方？回顾一下TCP协议头部，`Receive window`字段就是做这个的。接收方在每个确认片段（回复）中都带上当前的接收窗口大小。

发送方也对应地维护两个变量`LastByteSent`和`LastByteAcked`，他们相减就是当前未确认的数据量大小。发送方只要保持`未确认的大小<接收窗口`，就不会造成接收方缓冲区溢出。

但是要注意，如果接收窗口为0了，而且接收方也不给发送方发数据了（注意TCP是双工的），那么发送方永远也不会知道接收窗口什么时候打开。因此TCP规定，如果接收窗口为0，那么发送方要继续发送1byte的数据，以获得回复。

### 3.5.6 TCP连接管理

我们知道，发起连接的称为客户端，等待接受连接的称为服务端。

- 步骤一：客户端TCP先发一个特殊的片段过去，它不包含应用层数据，但是会将头部的一个flag`SYN`设置为1，因此这个特殊的片段也称为『SYN片段』。同时，还会随机生成一个初始化顺序号放在其中（这挺有趣的，是为了安全考虑）。
- 步骤二：当SYN片段到达服务端后，服务端就相应地为这个连接建立缓冲区、设置变量，并回复一个『连接许可片段』。这个片段也不包含数据，但是注意①SYN设为1；②确认号设置为顺序号+1；③初始化一个自己的顺序号并放进去（因为TCP是双工的！同时有顺序号和确认号）。这个片段也被称为『SYNACK』。
- 步骤三：在SYNACK返回客户端后，客户端也相应地建立缓冲区和变量。然后客户端要对SYNACK做一次回复，在这个片段中，要将确认号设置为服务端顺序号+1，并将SYN位设为0。此时也可以携带应用层数据了。

因为在建立连接的过程中来回发送了有三个片段，因此也称为『三次握手`three-way handshake`』。

> 在课后作业中有一些题目鼓励读者去深入探索TCP。比如为什么必须要初始化顺序号？为什么要三次握手而不是两次？值得一提的是，在攀岩运动中，攀爬者和他身后的保护者也是使用类似的三次握手机制。

TCP连接双方都可以终止连接。终止时，也要发出一个特殊的片段，其中flag`FIN`设置为1。另一方收到以后，还会回复一次，其中也将FIN设为1。此时，双方都释放连接的“资源”。

在一个连接的生命周期中，TCP会处在多个『TCP状态`states`』，详略。

> `SYN洪流攻击`是利用TCP握手机制来攻击服务器的手段。即尅可通过发送大量的SYN片段（即握手请求）到服务器，注意上面说的三次握手流程，服务器每接收一个SYN片段，就会将其视为一个连接并为其分配资源（缓冲区和变量）。而黑客发送端并不响应服务器的SYNACK片段（即不为这个连接分配资源），因此能以相对较小的资源造成很大的攻击效果。
> 应对方法是使用`SYN cookies`，即服务器收到第一次握手请求时，并不分配资源，而是将相关的变量保存在一个哈希表数据结构中（以客户端地址+端口号作为哈希函数输入值）；等客户端进行第三次握手之后，才分配资源。

那么，如果客户端请求握手时，服务端并没有在监听会怎么样？如果收到TCP片段，服务端会回复一个『RST片段(reset)』；如果收到UDP报文，回复『ICMP报文』。

> 一个强大的端口扫描工具是`nmap`，它能根据服务端响应的片段分析出很多信息。

## 3.6 拥塞控制的原则

我们接下来的讨论基于『异步传输模型`asynchronous transfer mode`(ATM)』网路的『可用速率`available bit-rate`(ABR)』。

### 3.6.1 拥塞产生的原因与后果

后果的意思就是，网络资源未被充分利用、终端看来性能很差。

#### 情景一：两个发送端，路由器缓存无限

有水桶效应，线路最大传输能力受限于线路中最差的那一段，设其为R。
发送端速率达到R/2时达到瓶颈；由于缓存无限，不会丢包，但因此延迟时间会很大（甚至无限）。

#### 情景二：两个发送端，路由器缓存有限

当发送总速率超过线路瓶颈R时，路由器会开始丢弃数据包，（而且如果认为超时）发送端也会进行重发。因此在线路中传输了一部分重发的数据包，总的利用率明显降低了，这就是拥塞的代价。

#### 情景三：多个发送端，多个路由器，每个连接跨越两个路由

非常接近于真实世界的网络情景，在这种情况下，单点的拥塞会导致连锁反应。
当发送端速率超过R/3时，有效速率急剧下降并趋于零。

### 3.6.2 控制拥塞的方法

- 点到点的控制：下面的网络层没有提供显式的支持，因此TCP必须要维护额外的信息。可以通过前面说的窗口来实现。
- 网络辅助的控制：由网络层设备（比如路由器）提供显式的、关于拥塞状况的反馈。反馈的数据包称为『窒息包`choke packet`』。


### 3.6.3 网络辅助控制示例：ATM-ABR拥塞控制

（在ATM术语中，用`cell`而不是`packet`，用`switch`而不是`router`）在ATM-ABR体系中，除了『数据包`data cell`』之外，还有少量的『资源管理包`resource-management cells`』；终端之间会互相发送RM，交换器本身也可以生成并发送RM。

ABR提供三个信号机制：

- `EFCI`bit：全称是『显式转发拥塞指示explicit forward congestion indication』，如果发生拥塞了，交换器会给目标终端发送一个EFCI设为1的RM包。
- `CI`和`NI`bit：全称是『拥塞指示congestion indication』和『不增指示no increase』。
- `ER`配置：全称是『显式速率explicit rate』，两个字节。

## 3.7 TCP拥塞控制

TCP必须使用点到点的拥塞控制机制，因为IP协议不提供支持。

TCP所采用的方法是，让每个发送端自己根据感知到的网络拥塞状况来限制发送的速率。如果TCP发送端感觉当前网络状况良好，就会提高速率；反之亦然。那么问题来了：如何限制发送速率？如何感知拥塞状态？如何根据拥塞状态决定发送速率？

TCP发送端维护了一个额外的变量，即『拥塞窗口`congestion window`(cwnd)』，回忆之前学的『接收窗口(rwnd)』，我们只需要控制未确认的数据长度比二者都小：

```text
LastByteSent – LastByteAcked <= min{cwnd, rwnd}
```

如果暂时不考虑rwnd，那么发送端最大发送速度会被限制为`cwnd/RTT`。

第二个问题，TCP发送端如何感知拥塞状况？很简单，发送方必须收到来自接收方的ACK消息后，才会更新rwnd，那么收到ACK越慢，rwnd增长地也就越慢，也就意味着发送速率越低。

第三个问题，如何决定速率？遵循三个原则：

- 丢包就减速。
- 正确收到ACK消息就提速。
- 以较小值启动，逐渐尝试加速；开始拥塞时降低速度，然后重新尝试加速；循环。

以三项原则为基础，我们有了『TCP拥塞控制算法』：

#### 慢启动

刚刚建立连接时，cwnd被设为`1 MSS`（注：MSS是一个TCP片段的长度），即此时初始速率为`MSS/RTT`。举个例子MSS=500bytes，RTT=200ms时，速率为20kbps。

然后收到1个ACK后，将cwnd增加1个MSS（此时为2，即同时发出2个片段）；然后收到2个ACK，将cwnd加2，以此类推。也就是说，速率会以指数级上涨。

何时停止指数上涨？首先，如果出现超时，则将cwnd重置为1（重新开始慢启动的过程）。第二，如果发现拥塞，记录此时的`cwnd/2`的值作为『慢启动阈值`ssthresh`』，并从『慢启动模式』转换为『避免拥塞模式』。第三，如果发现三个重复的ACK（即真的丢包了），就进入『快速恢复模式』。

#### 避免拥塞模式

在这个模式下，TCP不再将cwnd翻倍增长，而是每个RTT增加1个MSS。

#### 快速恢复模式

它并不是TCP的强制标准，而只是一个推荐元素。TCP早期版本`TCP Tahoe`会将cwnd重置为1，较新的版本`TCP Reno`会进入快速恢复模式。快速恢复模式会将ssthresh设为cwnd的一半，并将cwnd减半。

![2019-10-15-congestion-window.png](/static/blog/2019-10-15-congestion-window.png)

> 译者注：我认为这本教材讲解的很不好，英语表达不友好，而且概念解释得很混乱；简单的概念啰里啰嗦重复好几遍，复杂的概念又讲不清楚，比起os那本书差远了。  
> 这三个阶段的核心思想是：首先要记得慢启动，一开始速率很低然后以指数上升，到一定程度后以加法上升。当出现超时或者丢包情况时，将速率降低一半或者重置为最低。

#### TCP拥塞控制：可回溯的

由于上述的调整机制，cwnd随着时间推移会看起来像上下波动的“锯齿形”图案。这很好地解释了TCP的“带宽探测功能”。

#### TCP在高带宽路径的表现

值得提醒的是，TCP依然在不断发展。那些有利于SMTP、FTP、Telnet的特性未必是当前以HTTP主导的网络服务的最佳选择。

发展过程中必须要考虑的是高带宽的表现。例如，我们需要10Gpbs的速率，那么意味着cwnd大概是83333个片段长度，如此多的片段任何一个丢包了都会引起网速的巨大颠簸。通过一定的公式我们计算出，丢包率必须控制在0.000000002以内才能有效达到10Gpbs的速率。

### 3.7.1 拥塞控制的公平性

假设在某个网络节点上有K个TCP连接通过，而该节点的速率是R，那么当每个连接的速率都是R/K的时候我们认为是公平的。

（译者总结）从TCP的速率调整机制我们可以推导出，TCP会是公平的。假设某时刻A连接占用了所有的带宽（想象一个锯齿形），此时B连接开始慢启动；当A+B的速率超过R时，会出现丢包，那么A或者B会进入快速恢复模式并将速率减半。减半之后再次同时以线性速度上升；这样，多次减半之后，二者的速率自然就会达到一个相对公平的状态。

#### 与UDP的公平

UDP一般是语音或者视频数据流的选择，UDP协议没有拥塞控制机制，因此UDP会将TCP流量挤出去。

> 译者注：这里没有给出解决方案。UDP虽然没有拥塞控制看起来很糟糕，但是它不关心丢包的特性其实也是非常有用的，也许未来会基于UDP发展出一个有控制机制的新版协议。不过也许未来基础设施大幅改善，全都使用TCP也不是没有可能吧。

#### 并发TCP连接的公平

我们能限制的只是单个连接的公平，但是一个应用可以建立复数个TCP连接，以此争取更大的带宽份额。

## 3.8 小结

这一章从向应用层提供的服务开始讲起。一个极端是UDP，传输层仅提供最基础的服务，让应用层可以DIY；另一个极端是TCP，提供丰富并且相对可靠的传输服务。但是要注意的是，传输层能够提供的服务会受到下面网络层的限制，比如延迟和带宽就不能保证。

还要记住的是，理论上我们可以在连接层、网络层、传输层、应用层任意一层中实现可靠传输服务（可靠传输实质就是确认、计时、重发）。实际上，多年以来有很多开发者在这四层上都实现过，只不过目前主流的是TCP/IP而已。

我们还深入了解了一下TCP的原理，但是我们故意没有讲解TCP的变种，因为补丁、修复、改进版本太多了，我们在应用层是察觉不到的（因为应用程序都用socket进行操作，细节都被屏蔽了）。

最后讲了一些拥塞控制的机制。

我们这一章只关注了TCP和UDP两个主力协议，但是其实他们并不能完美适用于所有的场景。IETF（Internet Engineering Task Force）组织提议了一些新的标准：

- 『Datagram Congestion Control Protocol (DCCP)』提供一种低损耗、面向消息、类似UDP的不可靠传输，并附加了与TCP兼容的流量控制机制。
- 『Stream Control Transmission Protocol (SCTP)』与TCP相似，改进的地方是允许多个应用层数据流通过一个STCP连接进行传输（即减少连接数量）并允许数据通过不同的网络进行传输。
- 『TCP-Friendly Rate Control (TFRC)』是一种拥塞控制协议（而不是完善的传输层协议），它改进了TCP流量控制中的“锯齿状”速率波动。

（译者注：此书出版于2010年左右，以上协议可能不是最新的）只有未来才能证明这些改进协议是否好用，这取决于人们选择“更好”还是“足够好”。
