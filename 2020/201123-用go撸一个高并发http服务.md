```yaml lw-blog-meta
title: '用Go撸一个高并发HTTP服务'
date: "2020-11-23"
brev: "都说 http.Client 性能很烂，那么我们来从tcp开始手撸一个针对特定场景的高并发HTTP服务。"
tags: ["Golang","网络","技术分享会"]
```

## 背景

前面有提到过，我们公司最近组织了一次编程比赛。

赛题主要内容是： 写一个服务A，接收客户端请求后向服务B发起N次调用，并将N次调用的结果汇总返回。

这里吐槽一下，虽说我们是个以Python为主力语言的互联网公司，但是，当要比拼性能时，没一个人会用Python，大家都掏出了各种稀奇古怪的东西。~~说好的Python+C混合编程呢~~

在这样的环境下，我，为了稳妥地、优雅地给大家安利Go，选择了不用任何第三方框架，用纯粹的`http`库来实现服务端和请求端代码。然后最终的成绩还没"临时学了几个小时Go的同事"的好。~~别找借口了，输了就是输了~~

虽说排行榜前五名被Go语言包揽了四个，但是第一名居然是个Node，这让我不能再佛系下去了。~~不能再给Go丢人了~~

我把武德什么的抛在脑后，打算直接掏出TCP来针对性地来写这次的题目。于是便有了 [这份代码](https://github.com/Saodd/learn-go-tcp-http-worker) 和 这篇文章。

## 特别感谢

[v2ex - felix021 - 实战：150行Go实现高性能socks5代理](https://www.v2ex.com/t/727922#)

这位大佬的帖子虽然是在讲socks5协议，但是他深入浅出的讲解，让我想象到了http协议也能够按照类似的方法来实现。如果没有看到他这个帖子，我想我可能还要多走点弯路。

## 阶段一：从tcp读取http请求

首先我们从服务端开始，尝试去理解http的过程。

先搭建一个tcp服务器，我们先不做别的，仅仅从中读取所有的内容，然后关闭连接：

```go
func main() {
    server, err := net.Listen("tcp", "0.0.0.0:1080")
    if err != nil {
        logger.Fatalln(err)
    }
    for {
        conn, err := server.Accept()
        if err != nil {
            logger.Println(err)
            continue
        }
        go process(conn)
    }
}

func process(conn net.Conn) {
    remote := conn.RemoteAddr().String()
    defer func() {
        conn.Close()
        logger.Println(remote, "closed!")
    }()
    logger.Println(remote)
    buf := make([]byte, 4096) // 假定请求内容不超过4K字节
    _, err := conn.Read(buf)
    if err != nil {
        logger.Println(err)
        return
    }
    fmt.Println(string(buf))
}
```

然后我们试着用`curl`去调戏一下它：

```shell-session
$ curl localhost:1080/worker\?n\=100
```

```text
2020/11/23 18:25:10 main.go:33: [::1]:53221
GET /worker?n=100 HTTP/1.1
Host: localhost:1080
User-Agent: curl/7.64.1
Accept: */*


2020/11/23 18:25:10 main.go:31: [::1]:53221 closed!
```

在上面的中间夹着的部分，就是一个完整的http请求了。具体的协议格式我不详细讲了，不熟悉的同学可以参考我的另一篇博客 [190919-网络学习笔记2](https://lewinblog.com/blog/page/2019/190919-%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B02.md) 。

同理，由于我在最后是要比拼性能的，因此在这里我再确认一下`ab`在发送请求的时候会不会做一些多余的事情。然后答案是否定的：

```shell-session
ab -n1 -c1 http://localhost:1080/worker\?n\=100\&url\=http://worker:8000/worker
```

```text
GET /worker?n=100&url=http://worker:8000/worker HTTP/1.0
Host: localhost:1080
User-Agent: ApacheBench/2.3
Accept: */*

```

最后再从chrome中访问了一下，结果发现虽然塞了一堆cookie和乱七八糟的header，但是总长度也就1K字节左右，完全可控。

好，我们现在了解到了一个HTTP请求应该长什么样子，待会我们就可以照葫芦画瓢，构造出最精简的请求体。

## 阶段二：拼凑http请求发出去

为了性能优化，我这里必须直接上`HTTP/1.1`。

具体的实现思路就是，先用tcp建立连接，然后发送一个HTTP请求，读取响应；然后再发送一个请求，再读取一次响应，以验证`Keep-Alive`正常工作。

```go
const HttpRequest = `GET /worker HTTP/1.1
Host: any

`

func main() {
        conn, err := net.Dial("tcp", "127.0.0.1:8000")
        if err != nil {
            logger.Fatalln(err)
        }
        defer conn.Close()
    
        conn.Write([]byte(HttpRequest))
        buf := make([]byte, 4096) // 假定回复内容不超过4K字节
        conn.Read(buf)
        fmt.Println(string(buf))
    
        conn.Write([]byte(HttpRequest))
        // buf := make([]byte, 4096) // 不必清空buf
        conn.Read(buf)
        fmt.Println(string(buf))
}
```

这里要特别注意的是，根据HTTP协议，在GET请求体的最后一定是不多不少的2个`CRLF`，少了会导致请求失败，多了会导致连接断开（服务端：这个客户端有点毛病，不跟他玩）。

上面代码中的`:8000`是我启动的另外一个gin服务。因此上面代码运行结果大概是这样的：

```text
HTTP/1.1 200 OK
Content-Type: application/json; charset=utf-8
Date: Mon, 23 Nov 2020 11:19:07 GMT
Content-Length: 15

{"data":100013}
HTTP/1.1 200 OK
Content-Type: application/json; charset=utf-8
Date: Mon, 23 Nov 2020 11:19:08 GMT
Content-Length: 15

{"data":100014}
```

至此，我们已经确认了HTTP的请求体格式和响应体格式，接下来我们只要再解决一些业务上的琐碎细节，就可以开始考虑并发问题了。

## 阶段三：处理业务数据

这次的业务要求是：1个请求进来，发n个请求出去，求和然后返回。

因此我们的性能瓶颈在后面这n倍的请求里，因此我们仅对这个请求端的部分来手写优化。服务端的部分选用一个生产级别的web框架就可以了。

我们尝试从响应体中找到json字符串，然后进行解析：

```go
func OneCall() int {
    // ... 建立TCP连接的代码省略
    n, _ := conn.Read(buf)
    // 识别出json的部分
    index := bytes.Index(buf[:n], []byte("\r\n\r\n"))
    // 这里暂时不处理找不到的情况
    js := buf[index+4:n]
    var body WorkerBody
    err = json.Unmarshal(js, &body)
    return body.Data
}
```

## 阶段四：考虑并发

要想性能好，肯定避免不了「池」这个概念。

想一想，池子里的一个基本单元应该由什么构成？——只需要一个连接、一个缓冲区即可。

那么，一个「连接」，即一个`conn`对象，它到底是什么呢？从`net.Dail`的函数签名上看，它是一个interface；但是我们仔细追查一下，会发现在TCP的情况下它是`*net.TCPConn`对象；它实质上是个文件描述符对象。

很简单，我们只需要定义一个结构体把他们包起来就可以了：

```go
type ConnWorker struct {
    conn net.Conn
    buf  []byte
}

var ConnPool = sync.Pool{New: func() interface{} {
    return &ConnWorker{buf: make([]byte, 1024)}  // 1K字节对于这题来说足够了
}}

func OneCall(address string) int {
    w := ConnPool.Get().(*ConnWorker)
    defer ConnPool.Put(w)
    if w.conn == nil {
        conn, _ := net.Dial("tcp", address)  // 注：这里我是明确知道所有访问地址都是同一个
        w.conn = conn
    }
    // ... 发送请求体，读取响应体，解析json等
}
```

需要注意的是，在本篇文章里我省略了大量的错误处理机制，是为了突出逻辑重点，也是为了最快地实现原型。实际写代码的时候可别这么浪哦。

## 阶段五：补全业务代码，以及web框架

没什么技术含量，这部分省略。感兴趣的请去我的Github上看代码。

## 本地测试

先在本地随便跑一跑。测试条件：

1. 这里-n1200-c100，但是别忘记了每个请求后面需要有100倍的请求数量，所以这也是个`c10k`问题。
2. 硬件环境：e3v3老人机
3. 被请求的服务被设置为1000毫秒延时
4. 两个服务跑在同一台机器上，所以测试结果会很不准确

```text
Time taken for tests:   14.529 seconds
  50%   1037
  90%   1181
 100%   1687 (longest request)
```

## 优化一：重新连接机制

上面的代码，对于tcp连接并没有重连机制。如果因为某种原因（例如连接超时、或者上游服务重启），池子里的某个连接挂了，那么就会引发错误。

处理的方法很简单，加一个retry循环就可以了。详情请去看代码。

## 优化二：预先分配内存

我们在`ConnPool`里的对象，每个对象都是有一块1KB大小的缓冲区的。虽然看起来不大，但是如果每次都要去申请内存的话，也许可能似乎会影响那么一点点性能。

因此我们在`main`中加一段预热函数：

```go
func warmUp() {
    total := 10000
    temp := make([]interface{}, total)
    for i := range temp {
        temp[i] = ConnPool.Get()
    }
    for _, conn := range temp {
        ConnPool.Put(conn)
    }
}
```

那么这个预热能节省多少时间呢？我用下面的代码计算了一下，在我的mac上运行结果显示是 3.112602ms ，勉强算个蚊子腿吧。

```go
func warmUp() {
	t := time.Now()
	for i := 0; i < 10000; i++ {
		ConnPool.Get()
	}
	fmt.Println(time.Now().Sub(t).String())
}
```

## 优化三：禁用GC

其实我们的代码很简单，大概想一下，除了那个`cb chan int`会放在堆上，其他的变量应该都会被安排在栈上，因此GC方面应该是没有任何优化空间的。

不过我这里姑且记录一下设置的方法：

```go
debug.SetGCPercent(-1)
```

## 正式测试

由于本次比赛是在公司范围内举行，大家使用了各式各样的语言和框架来实现，虽然大家投入的精力不同，但也可以说是一个难得的对照环境。

测试条件是-n1200，所以在请求端总共有120k个请求。硬件条件2.6GHz-2核心-4GB。细节不说太多，说个总时间吧：

|time|语言|请求端QPS|
|---:|---:|---:|
|7.486 |Go|16.0k|
|9.341 |C++|12.8k|
|11.219 |Java|10.7k|
|11.807 |Node|10.1k|
|13.306 |Go|9.02k|
|21.064 |Nginx|5.70k|
|55.491 |Python(FastAPI+asyncio)|2.16k|

结论：优化过的GO > 随便写的C++ > 优化过的Node/Java > 随便写的Go

## QA List

1. 可以预先建立tcp连接吗？

    其实建立tcp连接才是在这个业务中真正的瓶颈。但是我们无法在程序启动时就建立10000个tcp连接，因为我们一开始并不知道客户端要求访问的服务地址。所以这个方案只能pass。

2. 没有错误处理？

    其实只是省略而已。加上错误处理也并不会对性能造成什么影响。而且重点是，参加比赛的代码没有谁会完整地考虑所有corner的。

3. 你的连接池都是针对一个host的！

    做个字典罢了，也不会影响性能的。

4. 你的HTTP请求都是固定的！想请求别的主机/路径都不行！

    无非就是写点bytes罢了，也不太影响性能的。可能需要给每个执行单元再多配一个写缓冲区。

5. 粘包警察："我怀疑你在犯罪"

    好吧，我可能需要强调一下，TCP的确是「流」，并不是"一波一波地"，并不是像我上面的代码那样读一次写一次读一次写一次的。但是，HTTP协议它就是"一次一次地"，我的处理是正常操作。

## 小结

用Go写一些底层的网络服务真的是太快乐了 ：）

在测试中发现一个小问题：Go服务的90%和100%档位的延迟相对较高。我想这是由于goroutine的特性导致的。但是Go的总吞吐量是最大的。

所以最后的灵魂拷问：现在你知道你的下一门语言该是什么了吧？
