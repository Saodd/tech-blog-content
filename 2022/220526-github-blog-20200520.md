```yaml lw-blog-meta
title: "[译]Three bugs in the Go MySQL Driver"
date: "2022-05-26"
brev: "学习一下 github.com 团队在 Go + MySQL 实践中踩过的坑"
tags: ["中间件"]
```

## 背景

今天我想了解一下 "mysql cluster" 使用方面的知识，结果发现了这篇文章，感觉讲得很好，而且是github这种世界顶级团队出品的文章，应该可以说是非常权威的。

其中最让我感兴趣的是，github团队在2020年就已经"在过去的几年里逐步将Rails重构为Go"。而我记得之前中文论坛中，总有人喜欢说"只有国内才用Go，外国人都不用，国人都是傻逼"这类言论。这篇文章足以证明一切。

看完之后感受：看大佬解决问题，真是一种享受啊。

## 原文信息

https://github.blog/2020-05-20-three-bugs-in-the-go-mysql-driver/

Vicent Martí, May 20, 2020

翻译：我自己。翻译过程中有较多地简化和意译。

## 前言

虽然 Github.com 依然是一个Rails构筑的庞然大物，但是在过去几年里我们开始逐步将关键功能从主应用中抽取出来，重构为Go —— 为了实现比Ruby更高的性能和可靠性 。

2019年我们上线了一个新的授权服务，叫做`authzd`，它是一个重要的里程碑，是我们第一个使用Go访问线上MySQl并处理web请求的服务。此前我们用Go写了一些基础架构，虽然也用到MySQL，但是那些都是写内部管理服务、异步批量任务。在一个普通的Rails请求中，可能会访问多次`authzd`服务，因此它的性能和可靠性非常重要。

除了上述挑战之外，由于`authzd`被部署在k8s集群上，它也遭遇了建立TCP连接时的高延迟问题。因此我们需要深入底层去研究我们依赖的库做了怎样的行为。

## The crash

长期以来，`"Invalid connection (unexpected EOF)"`是所有 Go MySQL bug中最常见的一个。之前我们在`gitbackups`这个服务中已经遭遇过了，但当时对于如何修复driver还未达成共识，因此当时我只在应用层代码中对它进行了修复。而当我们开始做`authzd`的时候，每分钟数百次的这个bug极大地增加了服务的故障率。

### 解决问题1

> 译者注：driver指的是特定的驱动，是一个接口声明，例如MySQL和Postgres他们分别有自己的driver实现。而database/sql是golang的标准库，是更高的抽象，而不管底层是MySQL还是Postgres或者什么东西。  
> 相关的源代码我应该是在写 [MySQL基本用法](../2022/220103-mysql-golang.md) 这篇博客的时候读过。

一个 Go SQL driver 的主要工作，其实就是给底层的`database/sql`标准库提供一个（个性化的）SQL连接。这个连接是有状态的，不支持并发（这是主流SQL服务器决定的特性）。`database/sql`负责使用和管理connection的生命周期。

`DB`结构体（通俗理解为"类"）则是你所有操作的入口，同时也是连接池的上层抽象。当对`DB`执行操作时，它会从连接池里取出一个active且idel的连接，或者通知driver创建一个新的连接；执行命令后，将连接放回连接池中或者销毁。

我们在业务中遭遇的`unexpected EOF`异常就发生在从连接池中取出连接并执行语句的时候。从MySQL日志中很容易推断：数据库正打算关闭那些闲置过久的（同时也是存在于DB连接池中的）连接。注意，我们的MySQL集群设置了一个激进的空闲限制时间：30秒。

对TCP连接来说，被关闭是很常见的事情。`database/sql`被设计为能够处理连接池中的连接被断开时的场景，并且特定的driver帮助处理。当任意的连接变得不健康时，driver会在下一次调用函数时返回一个`driver.ErrBadConn`错误。

`ErrBadConn`是一个神奇的咒语，会通知`database/sql`，如果连接在池子里那就把它移除，如果连接正在被使用那么就把它丢弃然后取一个新的。基于这种逻辑，我们在执行`(*DB).Query`命令的时候永远不会遇到"无效连接"这种错误，因为它会自动重试。

那么，为啥我们的`authzd`服务却遇到了"无效连接"错误？

这里有一些微妙的误解。TCP连接是全双工（`full-duplex`）的，双方都可以随时向对方发消息。而MySQL协议，在『`Command Phase`命令阶段』（即idle阶段）时是完全由客户端控制的，服务端仅仅会响应客户端的请求（译者注：类似HTTP协议）。而当服务端决定主动关闭连接时，问题出现了：

![网络流程图1](https://camo.githubusercontent.com/7f0fd5ef088b6b985e237e5ad51fe48407e5bca7f16f9237db2deaea2ad797eb/68747470733a2f2f692e696d6775722e636f6d2f743131434347642e706e67)

> 译者注：回想一下TCP的四次挥手，而在上图中只有两次挥手，此时TCP只在一个方向被关闭了，而客户端并没有发送FIN来关闭另一个方向。  
> 那么为啥客户端没有FIN呢？TCP应当是有通知应用层FIN消息的，而决定权在应用层，所以如果应用层（go driver）没有正确处理的话，TCP不会主动FIN的。

对很多TCP的应用层协议来说，这不会是个问题。正常情况下客户端会read，当读到FIN（以EOF形式）报文的时候，则会知道这个连接不能再用了。然而，在MySQL协议中，客户端会**先发请求，再读响应**（读和写不是并发的而是顺序的），所以结果就是向一个半关闭的连接中发送了数据，永远不会得到正确的响应，只有之前服务端发来的FIN报文（或者后续拒绝的RST报文），因此客户端读到了EOF。

OK，现在我们知道了连接为什么会崩溃了，那么为什么业务代码会崩溃呢？例如，为啥不返回一个`ErrBadConn`让它重试呢？

答案是：因为隐式重试在通常情况下是不安全的。回想一下：SQL语句已经被发送出去了，此时客户端并不能确定服务端是否收到，它只知道连接是半关闭状态，因此贸然重试是很危险的，必须由应用层来决定是否重试。

我们在`gitbackups`项目中采取的解决方案是，将`(*DB).SetConnMaxLifetime`的值设置为比MySQL服务器的最大闲置时间更短。注意了，这里设置的是 life-time ，而不是 idle-time ，因此它会导致活跃状态的连接也被无辜地关闭。
`database/sql`标准库没有提供关于 idle-time 的API，原因是：某些SQL服务器没有这个特性。啊哈，这可真是抽象的代价啊~
这个方案凑合能用吧，虽然会导致一些不必要的重连，而且当MySQL在高负载情况下主动关闭连接的场景也无法处理（即在小于预期时间的时候就关闭了连接）。

很显然，理想的解决方案应该是：当从连接池中取出连接的时候，主动检查连接的健康状态。然而，直到Go1.10版本推出`SessionResetter`接口之前都是做不到的。

有两种方式来检查连接的健康状态。其中之一是从MySQL层级，发送一个`PING`命令然后等待响应，这种情况下可以安全地返回`ErrBadConn`。这种方式很可靠，但是对性能有一定的影响。

因此我们选择了另一种方式，只检查TCP连接。检查TCP连接的代价比较小，我们只需要在TCP的任意写入之前先读取一次：如果服务器主动关闭了连接，那么会得到`EOF`错误；如果连接状态正常，那么会得到`EWOULDBLOCK`错误，意思是没有读到任何数据。这种方式有一点点性能代价，来自于Goroutine的调度机制，任何对socket的读取都是异步的，因此会有一轮不必要的沉睡-唤醒的切换代价。但是从Go1.9引入了`(*TCPConn).SyscallConn`允许我们直接访问底层的文件描述符，从而避免了这种不必要的开销。

根据这种思路，我提了一个 [PR](https://github.com/go-sql-driver/mysql/pull/934/files) ，这个额外的检查只会带来大约5微秒的性能损失。

将这项改动应用到我们的产品上之后，"无效连接"的BUG立即消失了，我们服务可用性终于达到了第一个"9"！

> 译者注：这才第一个9，未免有点惨吧……另外他这个PR有点意思，改一个BUG就把自己公司名字加到AUTHORS文件里去了，是我未曾设想过的道路。

### 上线提示1

- 你不再需要为处理idle而专门设置`(*DB).SetConnMaxLifetime`了！
- 妥善配置`SetMaxOpenConns()`和`SetMaxIdleConns()`以满足高峰时段的吞吐压力。

## The timeout

提醒一下我们的业务场景：在一个普通的web请求中，可能会多次访问`authzd`服务，因此我们必须严格控制这个服务的延迟。

在Go的世界里，那就是`context`，使用方法简单粗暴——在你每个函数参数中都加一个`context.Context`，这样你的整个应用都是可以随时取消的。

我们的研发团队出色地运用了Context，尤其是在MySQL操作上。然而，通过监控发现，Context的timeout功能并没有预期生效，依然有不少超时未取消的情况出现。

我怀疑是 Go MySQL driver 有问题，因此尝试从线上抓取了一个堆栈追踪信息，发现：Context的传递并没有我们想象得那么深入且完善。

我们发现在一种情况下，即连接池中没有连接而需要创建连接的时候，`driver.Driver.Open()`这个函数没有接受Context参数！ 建立一个MySQL连接意味着可能多达6次网络往返（TCP，SSL，MySQL），而他们都不在Context的控制之下。

要修复这个问题意味着巨大的重构工作。底层的问题可能要追溯到Go1.8引入的`QueryContext`和`ExecContext`，并且Go1.10引入的`Connector`是一套独立的实现；因此，要同时支持`driver.Driver`和`driver.Connector`非常麻烦，而且当时大家还普遍缺乏对这个BUG严重性的认识。

幸运的是，我很闲也有耐心，因此我又提了一个[PR](https://github.com/go-sql-driver/mysql/pull/941/files) ，效果显著。

### 上线提示2

- 你不必给`sql.(*DB)`主动配置新的`sql.OpenDB`，（只需要更新driver就好）。不过，主动配置`mysql.NewConnector`是有好处的，看你的需求了。
- 不要配置`mysql.(Config).Timeout`，没用。而是要正确使用`QeuryContext`或者`ExecContext`。

> 译者注：driver是有一套注册机制的，调用方会自动检测到，有兴趣可以看看源码。（有一套强大的标准库是真的香啊！）

## The race

我们说`sql.(*DB)`是连接池的抽象封装，然而实际上，做个比喻，我们每次执行SQL语句其实都是从连接池里**偷**了一个连接出来的。

当我们调用`(*DB).Query`的时候，是有返回值的，我们需要借助`sql.(*Rows)`来处理，最后还要调用`(*Rows).Close`这样连接才会放回到连接池内。代码书写方式基本没变过，像这样：

```go
func xxx(){
    rows, err := db.Query("SELECT a, b FROM some_table")
    if err != nil {
        return err
    }
    defer rows.Close()
    
    for rows.Next() {
        var a, b string
        if err := rows.Scan(&a, &b); err != nil {
            return err
        }
        ...
    }
}
```

上面的代码很清晰。在底层，每个driver实现了自己的`Rows`，然后被封装成`sql.(*Rows)`；每个driver没有实现自己的`Scan`，这部分在`database/sql`中复用了，driver只实现了`driver.Rows.Next` 。注意，在这个`Scan`的过程中，使用的缓冲区是借来的（连接中自带的）（这是一个正常且合理的优化）。

然而，还记得我们前面讨论的Context相关内容吗？（实际上从Go1.8引入了`QueryContext`开始）一个Query是有可能被打断的。此时，客户端被打断了、而MySQL服务器还在继续响应内容，因此我们需要在被打断的时候，"抽干"服务器的所有响应之后才能放心把连接放回连接池中。

问题出现了！在"抽干"的过程中，我们在反复覆盖缓冲区，这就会导致另一边同时正在执行的`Scan`函数读到有毒的数据！

有方法可以判断是否Scan到有毒数据吗？——有的，通过检查`rows.Close()`可以判断。然而现实是，绝绝绝大多数人（包括我）都会认为Close方法完全不必理会；（而且，检查它的返回值会让代码非常难受）。在Context之前，Scan可以检查到所有的错误，但是有了Context之后，你必须检查Close()的返回值！即使是 Go MySQL driver 修复这个问题，你也需要检查！

> 译者注：难怪我的lint总提示要我检查Close的返回值，不仅仅是 MySQL driver ，所有类似的Close方法都会提示。之前我还不以为然，今天读了这篇文章，才直到这个问题还是有点恐怖的。

如何解决？一种简单的方案，每次Scan的时候都把数据拷贝一遍，可这也太慢了，一直未被维护者采纳。这个我认为严重的BUG一直未被处理，因此我又来自己动手了。

我的第一个方案是，在"抽干"服务器响应的时候，我开辟一片新的缓冲区，这样就不会跟Scan产生竞争了嘛。可是很快我发现这个事情不可行，因为MySQL发过来的数据包会有各种格式、多种长度，（要是全部解析一遍那相当于重写了driver），所以我放弃了。

随后我想到另一个方案，也是最终被merged的方案——『双倍缓冲`double buffering`』。

在古老的计算机图形栈上，图形芯片计算出的画面像素会先写到缓冲区里，然后屏幕再从缓冲区里读取像素并显示出来；在两次读写的间隔，会产生『屏闪`flickering`』，它实际上就是一种可以被我们肉眼观察到的『数据竞争`data race`』。这个问题的改进方案，就是使用两块缓冲区交替读写：

![双倍缓冲](https://camo.githubusercontent.com/7739309b96621b94a7df12b963bd4b927a6e2a45e63a03b7e791f6634959c0b1/68747470733a2f2f692e696d6775722e636f6d2f54744b76625a372e676966)

> 译者注：卧槽，这个比喻太牛了，瞬间我就能理解到核心设计思想。不过其实这个方案的核心依然是开辟另一块缓冲区，只不过具体的实现方式与第一种方案略有不同罢了。

因此我用了类似的思想，当进入"抽干"阶段的时候，将缓冲区切换到另一块缓冲区上，因此只需要控制缓冲区指针即可，不需要改动其他逻辑！

这个方案的代价是需要额外的内存分配，不过随后我们做了一些优化，当真的需要"抽干"动作的时候，才会分配第二块缓冲区，这样对常规情况的影响就几乎没有了。小心地做过性能测试之后，我提交了[PR](https://github.com/go-sql-driver/mysql/pull/943) 

### 上线提示3

- 记得要检查`Close()`的返回值！养成好习惯！
- 不要扫描`sql.RawBytes`，因为它不会分配新的内存，会导致类似的数据竞争问题。因为虽然 MySQL driver 已经修复了，但是其他driver未必修了。可以用`[]byte`替代，它会拷贝。

## 小结

把新语言的代码部署上线真的是一项很有挑战的工作，特别是在Github这种用户数量庞大的产品上。以前我们常年压榨Ruby的MySQL客户端，现在我们开始压榨 Go MySQL driver 了。